{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Learn Sampling pattern\n\nA small pytorch example to showcase learning k-space sampling patterns.\nThis example showcases the auto-diff capabilities of the NUFFT operator \nwrt to k-space trajectory in mri-nufft.\n\nIn this example, we solve the following optimization problem:\n\n\\begin{align}\\mathbf{\\hat{K}} =  \\mathrm{arg} \\min_{\\mathbf{K}} ||  \\mathcal{F}_\\mathbf{K}^* D_\\mathbf{K} \\mathcal{F}_\\mathbf{K} \\mathbf{x} - \\mathbf{x} ||_2^2\\end{align}\nwhere $\\mathcal{F}_\\mathbf{K}$ is the forward NUFFT operator and $D_\\mathbf{K}$ is the density compensators for trajectory $\\mathbf{K}$,  $\\mathbf{x}$ is the MR image which is also the target image to be reconstructed.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>This example only showcases the autodiff capabilities, the learned sampling pattern is not scanner compliant as the scanner gradients required to implement it violate the hardware constraints. In practice, a projection $\\Pi_\\mathcal{Q}(\\mathbf{K})$ into the scanner constraints set $\\mathcal{Q}$ is recommended (see [Proj]_). This is implemented in the proprietary SPARKLING package [Sparks]_. Users are encouraged to contact the authors if they want to use it.</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport joblib\n\nimport brainweb_dl as bwdl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom tqdm import tqdm\nfrom PIL import Image, ImageSequence\n\nfrom mrinufft import get_operator\nfrom mrinufft.trajectories import initialize_2D_radial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup a simple class to learn trajectory\n<div class=\"alert alert-info\"><h4>Note</h4><p>While we are only learning the NUFFT operator, we still need the gradient ``wrt_data=True`` to be setup in ``get_operator`` to have all the gradients computed correctly.\n    See [Projector]_ for more details.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n    def __init__(self, inital_trajectory):\n        super(Model, self).__init__()\n        self.trajectory = torch.nn.Parameter(\n            data=torch.Tensor(inital_trajectory),\n            requires_grad=True,\n        )\n        self.operator = get_operator(\"gpunufft\", wrt_data=True, wrt_traj=True)(\n            self.trajectory.detach().cpu().numpy(),\n            shape=(256, 256),\n            density=True,\n            squeeze_dims=False,\n        )\n\n    def forward(self, x):\n        # Update the trajectory in the NUFFT operator.\n        # Note that the re-computation of density compensation happens internally.\n        self.operator.samples = self.trajectory.clone()\n\n        # A simple acquisition model simulated with a forward NUFFT operator\n        kspace = self.operator.op(x)\n\n        # A simple density compensated adjoint operator\n        adjoint = self.operator.adj_op(kspace)\n        return adjoint / torch.linalg.norm(adjoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Util function to plot the state of the model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_state(axs, mri_2D, traj, recon, loss=None, save_name=None):\n    axs = axs.flatten()\n    axs[0].imshow(np.abs(mri_2D[0]), cmap=\"gray\")\n    axs[0].axis(\"off\")\n    axs[0].set_title(\"MR Image\")\n    axs[1].scatter(*traj.T, s=1)\n    axs[1].set_title(\"Trajectory\")\n    axs[2].imshow(np.abs(recon[0][0].detach().cpu().numpy()), cmap=\"gray\")\n    axs[2].axis(\"off\")\n    axs[2].set_title(\"Reconstruction\")\n    if loss is not None:\n        axs[3].plot(loss)\n        axs[3].set_title(\"Loss\")\n        axs[3].grid(\"on\")\n    if save_name is not None:\n        plt.savefig(save_name, bbox_inches=\"tight\")\n        plt.close()\n    else:\n        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup model and optimizer\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "init_traj = initialize_2D_radial(16, 512).reshape(-1, 2).astype(np.float32)\nmodel = Model(init_traj)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nschedulder = torch.optim.lr_scheduler.LinearLR(\n    optimizer, start_factor=1, end_factor=0.1, total_iters=100\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mri_2D = torch.Tensor(np.flipud(bwdl.get_mri(4, \"T1\")[80, ...]).astype(np.complex64))[\n    None\n]\nmri_2D = mri_2D / torch.linalg.norm(mri_2D)\nmodel.eval()\nrecon = model(mri_2D)\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\nplot_state(axs, mri_2D, init_traj, recon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Start training loop\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "losses = []\nimage_files = []\nmodel.train()\nwith tqdm(range(100), unit=\"steps\") as tqdms:\n    for i in tqdms:\n        out = model(mri_2D)\n        loss = torch.norm(out - mri_2D[None])\n        numpy_loss = loss.detach().cpu().numpy()\n        tqdms.set_postfix({\"loss\": numpy_loss})\n        losses.append(numpy_loss)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        with torch.no_grad():\n            # Clamp the value of trajectory between [-0.5, 0.5]\n            for param in model.parameters():\n                param.clamp_(-0.5, 0.5)\n        schedulder.step()\n        # Generate images for gif\n        hashed = joblib.hash((i, \"learn_traj\", time.time()))\n        filename = \"/tmp/\" + f\"{hashed}.png\"\n        fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n        plot_state(\n            axs,\n            mri_2D,\n            model.trajectory.detach().cpu().numpy(),\n            out,\n            losses,\n            save_name=filename,\n        )\n        image_files.append(filename)\n\n\n# Make a GIF of all images.\nimgs = [Image.open(img) for img in image_files]\nimgs[0].save(\n    \"mrinufft_learn_traj.gif\",\n    save_all=True,\n    append_images=imgs[1:],\n    optimize=False,\n    duration=2,\n    loop=0,\n)\n\n# sphinx_gallery_thumbnail_path = 'generated/autoexamples/GPU/images/mrinufft_learn_traj.gif'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. image-sg:: /generated/autoexamples/GPU/images/mrinufft_learn_traj.gif\n   :alt: example learn_samples\n   :srcset: /generated/autoexamples/GPU/images/mrinufft_learn_traj.gif\n   :class: sphx-glr-single-img\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trained trajectory\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.eval()\nrecon = model(mri_2D)\nfig, axs = plt.subplots(2, 2, figsize=(10, 10))\nplot_state(axs, mri_2D, model.trajectory.detach().cpu().numpy(), recon, losses)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### References\n\n.. [Proj] N. Chauffert, P. Weiss, J. Kahn and P. Ciuciu, \"A Projection Algorithm for\n          Gradient Waveforms Design in Magnetic Resonance Imaging,\" in\n          IEEE Transactions on Medical Imaging, vol. 35, no. 9, pp. 2026-2039, Sept. 2016,\n          doi: 10.1109/TMI.2016.2544251.\n.. [Sparks] Chaithya GR, P. Weiss, G. Daval-Fr\u00e9rot, A. Massire, A. Vignaud and P. Ciuciu,\n          \"Optimizing Full 3D SPARKLING Trajectories for High-Resolution Magnetic\n          Resonance Imaging,\" in IEEE Transactions on Medical Imaging, vol. 41, no. 8,\n          pp. 2105-2117, Aug. 2022, doi: 10.1109/TMI.2022.3157269.\n.. [Projector] Chaithya GR, and Philippe Ciuciu. 2023. \"Jointly Learning Non-Cartesian\n          k-Space Trajectories and Reconstruction Networks for 2D and 3D MR Imaging\n          through Projection\" Bioengineering 10, no. 2: 158.\n          https://doi.org/10.3390/bioengineering10020158\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}