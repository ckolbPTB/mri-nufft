
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "generated/autoexamples/GPU/example_learn_straight_line_readouts.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_generated_autoexamples_GPU_example_learn_straight_line_readouts.py>`
        to download the full example code. or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_generated_autoexamples_GPU_example_learn_straight_line_readouts.py:


===================================
Learn Straight line readout pattern
===================================

A small pytorch example to showcase learning k-space sampling patterns.
In this example we learn the 2D sampling pattern for a 3D MRI image, assuming
straight line readouts. This example showcases the auto-diff capabilities of the NUFFT operator
The image resolution is kept small to reduce computation time.

.. warning::
    This example only showcases the autodiff capabilities, the learned sampling pattern is not scanner compliant as the scanner gradients required to implement it violate the hardware constraints. In practice, a projection :math:`\Pi_\mathcal{Q}(\mathbf{K})` into the scanner constraints set :math:`\mathcal{Q}` is recommended (see [Proj]_). This is implemented in the proprietary SPARKLING package [Sparks]_. Users are encouraged to contact the authors if they want to use it.

.. GENERATED FROM PYTHON SOURCE LINES 17-21

.. colab-link::
   :needs_gpu: 1

   !pip install mri-nufft[gpunufft]

.. GENERATED FROM PYTHON SOURCE LINES 24-26

Imports
-------

.. GENERATED FROM PYTHON SOURCE LINES 26-39

.. code-block:: Python

    import time
    import joblib

    import brainweb_dl as bwdl
    import matplotlib.pyplot as plt
    import numpy as np
    import torch
    from tqdm import tqdm
    from PIL import Image, ImageSequence

    from mrinufft import get_operator









.. GENERATED FROM PYTHON SOURCE LINES 40-45

Setup a simple class to learn trajectory
----------------------------------------
.. note::
    While we are only learning the NUFFT operator, we still need the gradient `wrt_data=True` to have all the gradients computed correctly.
    See [Projector]_ for more details.

.. GENERATED FROM PYTHON SOURCE LINES 45-115

.. code-block:: Python



    class Model(torch.nn.Module):
        def __init__(self, num_shots, img_size, factor_cartesian=0.3):
            super(Model, self).__init__()
            self.num_samples_per_shot = 128
            cart_del = 1 / img_size[0]
            num_cart_points = np.round(np.sqrt(factor_cartesian * num_shots)).astype(int)
            edge_center = cart_del * num_cart_points / 2

            self.central_points = torch.nn.Parameter(
                data=torch.stack(
                    torch.meshgrid(
                        torch.linspace(-edge_center, edge_center, num_cart_points),
                        torch.linspace(-edge_center, edge_center, num_cart_points),
                        indexing="ij",
                    ),
                    axis=-1,
                ).reshape(-1, 2),
                requires_grad=False,
            )
            self.non_center_points = torch.nn.Parameter(
                data=torch.Tensor(
                    np.random.random((num_shots - self.central_points.shape[0], 2)) - 0.5
                ),
                requires_grad=True,
            )
            self.operator = get_operator("gpunufft", wrt_data=True, wrt_traj=True)(
                np.random.random(
                    (self.get_2D_points().shape[0] * self.num_samples_per_shot, 3)
                )
                - 0.5,
                shape=img_size,
                density=True,
                squeeze_dims=False,
            )

        def get_trajectory(self, get_as_shot=False):
            samples = self._get_3D_points(self.get_2D_points())
            if not get_as_shot:
                return samples
            return samples.reshape(-1, self.num_samples_per_shot, 3)

        def get_2D_points(self):
            return torch.vstack([self.central_points, self.non_center_points])

        def _get_3D_points(self, samples2D):
            line = torch.linspace(
                -0.5,
                0.5,
                self.num_samples_per_shot,
                device=samples2D.device,
                dtype=samples2D.dtype,
            )
            return torch.stack(
                [
                    line.repeat(samples2D.shape[0], 1),
                    samples2D[:, 0].repeat(self.num_samples_per_shot, 1).T,
                    samples2D[:, 1].repeat(self.num_samples_per_shot, 1).T,
                ],
                dim=-1,
            ).reshape(-1, 3)

        def forward(self, x):
            self.operator.samples = self.get_trajectory()
            kspace = self.operator.op(x)
            adjoint = self.operator.adj_op(kspace).abs()
            return adjoint / torch.mean(adjoint)









.. GENERATED FROM PYTHON SOURCE LINES 116-118

Util function to plot the state of the model
--------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 118-163

.. code-block:: Python



    def plot_state(mri_2D, traj, recon, loss=None, save_name=None, i=None):
        fig_grid = (2, 2)
        if loss is None:
            fig_grid = (1, 3)
        fig, axs = plt.subplots(*fig_grid, figsize=tuple(i * 5 for i in fig_grid[::-1]))
        axs = axs.flatten()
        axs[0].imshow(np.abs(mri_2D[0][..., 11]), cmap="gray")
        axs[0].axis("off")
        axs[0].set_title("MR Image")
        if traj.shape[-1] == 3:
            if i is not None and i > 50:
                axs[1].scatter(*traj.T[1:3, 0], s=10, color="blue")
            else:
                fig_kwargs = {}
                plt_kwargs = {"s": 1, "alpha": 0.2}
                if i is not None:
                    fig_kwargs["azim"], fig_kwargs["elev"] = (
                        i / 50 * 60 - 60,
                        30 - i / 50 * 30,
                    )
                    plt_kwargs["alpha"] = 0.2 + 0.8 * i / 50
                    plt_kwargs["s"] = 1 + 9 * i / 50
                axs[1].remove()
                axs[1] = fig.add_subplot(*fig_grid, 2, projection="3d", **fig_kwargs)
                for shot in traj:
                    axs[1].scatter(*shot.T, color="blue", **plt_kwargs)
        else:
            axs[1].scatter(*traj.T, s=10)
        axs[1].set_title("Trajectory")
        axs[2].imshow(np.abs(recon[0][0][..., 11].detach().cpu().numpy()), cmap="gray")
        axs[2].axis("off")
        axs[2].set_title("Reconstruction")
        if loss is not None:
            axs[3].plot(loss)
            axs[3].grid("on")
            axs[3].set_title("Loss")
        if save_name is not None:
            plt.savefig(save_name, bbox_inches="tight")
            plt.close()
        else:
            plt.show()









.. GENERATED FROM PYTHON SOURCE LINES 164-166

Setup model and optimizer
-------------------------

.. GENERATED FROM PYTHON SOURCE LINES 166-170

.. code-block:: Python


    cart_data = np.flipud(bwdl.get_mri(4, "T1")).T[::8, ::8, ::8].astype(np.complex64)
    model = Model(253, cart_data.shape)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)







.. GENERATED FROM PYTHON SOURCE LINES 171-173

Setup data
----------

.. GENERATED FROM PYTHON SOURCE LINES 173-179

.. code-block:: Python


    mri_3D = torch.Tensor(cart_data)[None]
    mri_3D = mri_3D / torch.mean(mri_3D)
    model.eval()
    recon = model(mri_3D)
    plot_state(mri_3D, model.get_trajectory(True).detach().cpu().numpy(), recon)



.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_learn_straight_line_readouts_001.png
   :alt: MR Image, Reconstruction, Trajectory
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_learn_straight_line_readouts_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 180-182

Start training loop
-------------------

.. GENERATED FROM PYTHON SOURCE LINES 182-225

.. code-block:: Python

    losses = []
    image_files = []
    model.train()
    with tqdm(range(100), unit="steps") as tqdms:
        for i in tqdms:
            out = model(mri_3D)
            loss = torch.nn.functional.mse_loss(out, mri_3D[None])
            numpy_loss = loss.detach().cpu().numpy()
            tqdms.set_postfix({"loss": numpy_loss})
            losses.append(numpy_loss)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            with torch.no_grad():
                # Clamp the value of trajectory between [-0.5, 0.5]
                for param in model.parameters():
                    param.clamp_(-0.5, 0.5)
            # Generate images for gif
            hashed = joblib.hash((i, "learn_line", time.time()))
            filename = "/tmp/" + f"{hashed}.png"
            plot_state(
                mri_3D,
                model.get_trajectory(True).detach().cpu().numpy(),
                out,
                losses,
                save_name=filename,
                i=i,
            )
            image_files.append(filename)

    # Make a GIF of all images.
    imgs = [Image.open(img) for img in image_files]
    imgs[0].save(
        "mrinufft_learn_2d_sampling_pattern.gif",
        save_all=True,
        append_images=imgs[1:],
        optimize=False,
        duration=2,
        loop=0,
    )

    # sphinx_gallery_thumbnail_path = 'generated/autoexamples/GPU/images/mrinufft_learn_2d_sampling_pattern.gif'





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/100 [00:00<?, ?steps/s]      0%|          | 0/100 [00:00<?, ?steps/s, loss=0.32001835]      1%|          | 1/100 [00:03<06:34,  3.99s/steps, loss=0.32001835]      1%|          | 1/100 [00:04<06:34,  3.99s/steps, loss=0.2837842]       2%|▏         | 2/100 [00:08<07:05,  4.34s/steps, loss=0.2837842]      2%|▏         | 2/100 [00:08<07:05,  4.34s/steps, loss=0.2760641]      3%|▎         | 3/100 [00:12<06:45,  4.19s/steps, loss=0.2760641]      3%|▎         | 3/100 [00:12<06:45,  4.19s/steps, loss=0.26738268]      4%|▍         | 4/100 [00:16<06:42,  4.19s/steps, loss=0.26738268]      4%|▍         | 4/100 [00:16<06:42,  4.19s/steps, loss=0.2590558]       5%|▌         | 5/100 [00:21<06:49,  4.31s/steps, loss=0.2590558]      5%|▌         | 5/100 [00:21<06:49,  4.31s/steps, loss=0.25516763]      6%|▌         | 6/100 [00:25<06:35,  4.21s/steps, loss=0.25516763]      6%|▌         | 6/100 [00:25<06:35,  4.21s/steps, loss=0.25664857]      7%|▋         | 7/100 [00:30<06:48,  4.39s/steps, loss=0.25664857]      7%|▋         | 7/100 [00:30<06:48,  4.39s/steps, loss=0.2547159]       8%|▊         | 8/100 [00:33<06:27,  4.21s/steps, loss=0.2547159]      8%|▊         | 8/100 [00:33<06:27,  4.21s/steps, loss=0.24778265]      9%|▉         | 9/100 [00:38<06:31,  4.30s/steps, loss=0.24778265]      9%|▉         | 9/100 [00:38<06:31,  4.30s/steps, loss=0.24256076]     10%|█         | 10/100 [00:42<06:32,  4.37s/steps, loss=0.24256076]     10%|█         | 10/100 [00:42<06:32,  4.37s/steps, loss=0.24029678]     11%|█         | 11/100 [00:47<06:21,  4.29s/steps, loss=0.24029678]     11%|█         | 11/100 [00:47<06:21,  4.29s/steps, loss=0.23903179]     12%|█▏        | 12/100 [00:51<06:09,  4.20s/steps, loss=0.23903179]     12%|█▏        | 12/100 [00:51<06:09,  4.20s/steps, loss=0.23699395]     13%|█▎        | 13/100 [00:55<06:17,  4.34s/steps, loss=0.23699395]     13%|█▎        | 13/100 [00:55<06:17,  4.34s/steps, loss=0.23571397]     14%|█▍        | 14/100 [00:59<06:11,  4.32s/steps, loss=0.23571397]     14%|█▍        | 14/100 [01:00<06:11,  4.32s/steps, loss=0.23548895]     15%|█▌        | 15/100 [01:04<06:11,  4.37s/steps, loss=0.23548895]     15%|█▌        | 15/100 [01:04<06:11,  4.37s/steps, loss=0.23612781]     16%|█▌        | 16/100 [01:08<06:02,  4.32s/steps, loss=0.23612781]     16%|█▌        | 16/100 [01:08<06:02,  4.32s/steps, loss=0.23517588]     17%|█▋        | 17/100 [01:12<05:55,  4.29s/steps, loss=0.23517588]     17%|█▋        | 17/100 [01:12<05:55,  4.29s/steps, loss=0.23316208]     18%|█▊        | 18/100 [01:17<05:57,  4.36s/steps, loss=0.23316208]     18%|█▊        | 18/100 [01:17<05:57,  4.36s/steps, loss=0.2311646]      19%|█▉        | 19/100 [01:21<05:48,  4.30s/steps, loss=0.2311646]     19%|█▉        | 19/100 [01:21<05:48,  4.30s/steps, loss=0.2299716]     20%|██        | 20/100 [01:25<05:44,  4.30s/steps, loss=0.2299716]     20%|██        | 20/100 [01:25<05:44,  4.30s/steps, loss=0.22904205]     21%|██        | 21/100 [01:30<05:43,  4.35s/steps, loss=0.22904205]     21%|██        | 21/100 [01:30<05:43,  4.35s/steps, loss=0.22832838]     22%|██▏       | 22/100 [01:34<05:35,  4.31s/steps, loss=0.22832838]     22%|██▏       | 22/100 [01:34<05:35,  4.31s/steps, loss=0.22770488]     23%|██▎       | 23/100 [01:39<05:38,  4.40s/steps, loss=0.22770488]     23%|██▎       | 23/100 [01:39<05:38,  4.40s/steps, loss=0.22775614]     24%|██▍       | 24/100 [01:43<05:32,  4.37s/steps, loss=0.22775614]     24%|██▍       | 24/100 [01:43<05:32,  4.37s/steps, loss=0.22771578]     25%|██▌       | 25/100 [01:47<05:15,  4.21s/steps, loss=0.22771578]     25%|██▌       | 25/100 [01:47<05:15,  4.21s/steps, loss=0.22704299]     26%|██▌       | 26/100 [01:51<05:17,  4.29s/steps, loss=0.22704299]     26%|██▌       | 26/100 [01:51<05:17,  4.29s/steps, loss=0.22584824]     27%|██▋       | 27/100 [01:56<05:14,  4.30s/steps, loss=0.22584824]     27%|██▋       | 27/100 [01:56<05:14,  4.30s/steps, loss=0.22457764]     28%|██▊       | 28/100 [02:00<05:05,  4.24s/steps, loss=0.22457764]     28%|██▊       | 28/100 [02:00<05:05,  4.24s/steps, loss=0.22394022]     29%|██▉       | 29/100 [02:04<05:06,  4.32s/steps, loss=0.22394022]     29%|██▉       | 29/100 [02:04<05:06,  4.32s/steps, loss=0.2236778]      30%|███       | 30/100 [02:08<04:49,  4.14s/steps, loss=0.2236778]     30%|███       | 30/100 [02:08<04:49,  4.14s/steps, loss=0.22322841]     31%|███       | 31/100 [02:12<04:48,  4.18s/steps, loss=0.22322841]     31%|███       | 31/100 [02:12<04:48,  4.18s/steps, loss=0.2229644]      32%|███▏      | 32/100 [02:16<04:38,  4.10s/steps, loss=0.2229644]     32%|███▏      | 32/100 [02:16<04:38,  4.10s/steps, loss=0.22289895]     33%|███▎      | 33/100 [02:20<04:27,  4.00s/steps, loss=0.22289895]     33%|███▎      | 33/100 [02:20<04:27,  4.00s/steps, loss=0.22280757]     34%|███▍      | 34/100 [02:24<04:35,  4.17s/steps, loss=0.22280757]     34%|███▍      | 34/100 [02:25<04:35,  4.17s/steps, loss=0.22245665]     35%|███▌      | 35/100 [02:28<04:26,  4.11s/steps, loss=0.22245665]     35%|███▌      | 35/100 [02:28<04:26,  4.11s/steps, loss=0.22178592]     36%|███▌      | 36/100 [02:32<04:21,  4.08s/steps, loss=0.22178592]     36%|███▌      | 36/100 [02:32<04:21,  4.08s/steps, loss=0.2209078]      37%|███▋      | 37/100 [02:37<04:20,  4.14s/steps, loss=0.2209078]     37%|███▋      | 37/100 [02:37<04:20,  4.14s/steps, loss=0.22065178]     38%|███▊      | 38/100 [02:41<04:13,  4.09s/steps, loss=0.22065178]     38%|███▊      | 38/100 [02:41<04:13,  4.09s/steps, loss=0.22034958]     39%|███▉      | 39/100 [02:45<04:09,  4.10s/steps, loss=0.22034958]     39%|███▉      | 39/100 [02:45<04:09,  4.10s/steps, loss=0.22017097]     40%|████      | 40/100 [02:49<04:11,  4.19s/steps, loss=0.22017097]     40%|████      | 40/100 [02:49<04:11,  4.19s/steps, loss=0.2201572]      41%|████      | 41/100 [02:53<04:06,  4.18s/steps, loss=0.2201572]     41%|████      | 41/100 [02:53<04:06,  4.18s/steps, loss=0.22005945]     42%|████▏     | 42/100 [02:58<04:08,  4.28s/steps, loss=0.22005945]     42%|████▏     | 42/100 [02:58<04:08,  4.28s/steps, loss=0.22027136]     43%|████▎     | 43/100 [03:02<04:09,  4.38s/steps, loss=0.22027136]     43%|████▎     | 43/100 [03:03<04:09,  4.38s/steps, loss=0.22052205]     44%|████▍     | 44/100 [03:07<04:09,  4.45s/steps, loss=0.22052205]     44%|████▍     | 44/100 [03:07<04:09,  4.45s/steps, loss=0.22023095]     45%|████▌     | 45/100 [03:12<04:12,  4.59s/steps, loss=0.22023095]     45%|████▌     | 45/100 [03:12<04:12,  4.59s/steps, loss=0.2195618]      46%|████▌     | 46/100 [03:16<03:53,  4.33s/steps, loss=0.2195618]     46%|████▌     | 46/100 [03:16<03:53,  4.33s/steps, loss=0.21891844]     47%|████▋     | 47/100 [03:19<03:39,  4.15s/steps, loss=0.21891844]     47%|████▋     | 47/100 [03:20<03:39,  4.15s/steps, loss=0.2187852]      48%|████▊     | 48/100 [03:24<03:37,  4.18s/steps, loss=0.2187852]     48%|████▊     | 48/100 [03:24<03:37,  4.18s/steps, loss=0.21861486]     49%|████▉     | 49/100 [03:28<03:27,  4.06s/steps, loss=0.21861486]     49%|████▉     | 49/100 [03:28<03:27,  4.06s/steps, loss=0.21849611]     50%|█████     | 50/100 [03:32<03:26,  4.12s/steps, loss=0.21849611]     50%|█████     | 50/100 [03:32<03:26,  4.12s/steps, loss=0.21828844]     51%|█████     | 51/100 [03:36<03:23,  4.14s/steps, loss=0.21828844]     51%|█████     | 51/100 [03:36<03:23,  4.14s/steps, loss=0.21807161]     52%|█████▏    | 52/100 [03:37<02:28,  3.10s/steps, loss=0.21807161]     52%|█████▏    | 52/100 [03:37<02:28,  3.10s/steps, loss=0.21770562]     53%|█████▎    | 53/100 [03:37<01:50,  2.35s/steps, loss=0.21770562]     53%|█████▎    | 53/100 [03:37<01:50,  2.35s/steps, loss=0.21750295]     54%|█████▍    | 54/100 [03:38<01:24,  1.83s/steps, loss=0.21750295]     54%|█████▍    | 54/100 [03:38<01:24,  1.83s/steps, loss=0.21729966]     55%|█████▌    | 55/100 [03:38<01:06,  1.47s/steps, loss=0.21729966]     55%|█████▌    | 55/100 [03:39<01:06,  1.47s/steps, loss=0.21692276]     56%|█████▌    | 56/100 [03:39<00:53,  1.22s/steps, loss=0.21692276]     56%|█████▌    | 56/100 [03:39<00:53,  1.22s/steps, loss=0.2168115]      57%|█████▋    | 57/100 [03:40<00:49,  1.16s/steps, loss=0.2168115]     57%|█████▋    | 57/100 [03:40<00:49,  1.16s/steps, loss=0.21668899]     58%|█████▊    | 58/100 [03:41<00:41,  1.02steps/s, loss=0.21668899]     58%|█████▊    | 58/100 [03:41<00:41,  1.02steps/s, loss=0.21647976]     59%|█████▉    | 59/100 [03:41<00:35,  1.17steps/s, loss=0.21647976]     59%|█████▉    | 59/100 [03:41<00:35,  1.17steps/s, loss=0.21638776]     60%|██████    | 60/100 [03:42<00:31,  1.28steps/s, loss=0.21638776]     60%|██████    | 60/100 [03:42<00:31,  1.28steps/s, loss=0.21616426]     61%|██████    | 61/100 [03:42<00:28,  1.37steps/s, loss=0.21616426]     61%|██████    | 61/100 [03:43<00:28,  1.37steps/s, loss=0.21610478]     62%|██████▏   | 62/100 [03:43<00:27,  1.41steps/s, loss=0.21610478]     62%|██████▏   | 62/100 [03:43<00:27,  1.41steps/s, loss=0.21606478]     63%|██████▎   | 63/100 [03:44<00:25,  1.43steps/s, loss=0.21606478]     63%|██████▎   | 63/100 [03:44<00:25,  1.43steps/s, loss=0.2161909]      64%|██████▍   | 64/100 [03:45<00:25,  1.44steps/s, loss=0.2161909]     64%|██████▍   | 64/100 [03:45<00:25,  1.44steps/s, loss=0.21609381]     65%|██████▌   | 65/100 [03:45<00:24,  1.45steps/s, loss=0.21609381]     65%|██████▌   | 65/100 [03:45<00:24,  1.45steps/s, loss=0.21589316]     66%|██████▌   | 66/100 [03:46<00:28,  1.19steps/s, loss=0.21589316]     66%|██████▌   | 66/100 [03:46<00:28,  1.19steps/s, loss=0.21573399]     67%|██████▋   | 67/100 [03:47<00:26,  1.27steps/s, loss=0.21573399]     67%|██████▋   | 67/100 [03:47<00:26,  1.27steps/s, loss=0.21542591]     68%|██████▊   | 68/100 [03:48<00:24,  1.32steps/s, loss=0.21542591]     68%|██████▊   | 68/100 [03:48<00:24,  1.32steps/s, loss=0.21525657]     69%|██████▉   | 69/100 [03:48<00:22,  1.36steps/s, loss=0.21525657]     69%|██████▉   | 69/100 [03:48<00:22,  1.36steps/s, loss=0.21511202]     70%|███████   | 70/100 [03:49<00:21,  1.41steps/s, loss=0.21511202]     70%|███████   | 70/100 [03:49<00:21,  1.41steps/s, loss=0.21501264]     71%|███████   | 71/100 [03:50<00:19,  1.45steps/s, loss=0.21501264]     71%|███████   | 71/100 [03:50<00:19,  1.45steps/s, loss=0.21498272]     72%|███████▏  | 72/100 [03:50<00:19,  1.45steps/s, loss=0.21498272]     72%|███████▏  | 72/100 [03:50<00:19,  1.45steps/s, loss=0.21503948]     73%|███████▎  | 73/100 [03:51<00:18,  1.42steps/s, loss=0.21503948]     73%|███████▎  | 73/100 [03:51<00:18,  1.42steps/s, loss=0.21527275]     74%|███████▍  | 74/100 [03:52<00:21,  1.23steps/s, loss=0.21527275]     74%|███████▍  | 74/100 [03:52<00:21,  1.23steps/s, loss=0.21516705]     75%|███████▌  | 75/100 [03:53<00:19,  1.27steps/s, loss=0.21516705]     75%|███████▌  | 75/100 [03:53<00:19,  1.27steps/s, loss=0.21499272]     76%|███████▌  | 76/100 [03:54<00:17,  1.35steps/s, loss=0.21499272]     76%|███████▌  | 76/100 [03:54<00:17,  1.35steps/s, loss=0.2149769]      77%|███████▋  | 77/100 [03:54<00:16,  1.44steps/s, loss=0.2149769]     77%|███████▋  | 77/100 [03:54<00:16,  1.44steps/s, loss=0.21503809]     78%|███████▊  | 78/100 [03:55<00:15,  1.45steps/s, loss=0.21503809]     78%|███████▊  | 78/100 [03:55<00:15,  1.45steps/s, loss=0.21502864]     79%|███████▉  | 79/100 [03:55<00:14,  1.47steps/s, loss=0.21502864]     79%|███████▉  | 79/100 [03:56<00:14,  1.47steps/s, loss=0.21507558]     80%|████████  | 80/100 [03:56<00:13,  1.50steps/s, loss=0.21507558]     80%|████████  | 80/100 [03:56<00:13,  1.50steps/s, loss=0.21491708]     81%|████████  | 81/100 [03:57<00:12,  1.50steps/s, loss=0.21491708]     81%|████████  | 81/100 [03:57<00:12,  1.50steps/s, loss=0.21474297]     82%|████████▏ | 82/100 [03:57<00:11,  1.50steps/s, loss=0.21474297]     82%|████████▏ | 82/100 [03:58<00:11,  1.50steps/s, loss=0.21461645]     83%|████████▎ | 83/100 [03:59<00:14,  1.21steps/s, loss=0.21461645]     83%|████████▎ | 83/100 [03:59<00:14,  1.21steps/s, loss=0.21452473]     84%|████████▍ | 84/100 [03:59<00:12,  1.30steps/s, loss=0.21452473]     84%|████████▍ | 84/100 [03:59<00:12,  1.30steps/s, loss=0.21450065]     85%|████████▌ | 85/100 [04:00<00:11,  1.32steps/s, loss=0.21450065]     85%|████████▌ | 85/100 [04:00<00:11,  1.32steps/s, loss=0.21434197]     86%|████████▌ | 86/100 [04:01<00:09,  1.43steps/s, loss=0.21434197]     86%|████████▌ | 86/100 [04:01<00:09,  1.43steps/s, loss=0.21417534]     87%|████████▋ | 87/100 [04:01<00:09,  1.42steps/s, loss=0.21417534]     87%|████████▋ | 87/100 [04:01<00:09,  1.42steps/s, loss=0.21414967]     88%|████████▊ | 88/100 [04:02<00:08,  1.45steps/s, loss=0.21414967]     88%|████████▊ | 88/100 [04:02<00:08,  1.45steps/s, loss=0.21414162]     89%|████████▉ | 89/100 [04:03<00:07,  1.48steps/s, loss=0.21414162]     89%|████████▉ | 89/100 [04:03<00:07,  1.48steps/s, loss=0.21415113]     90%|█████████ | 90/100 [04:03<00:06,  1.50steps/s, loss=0.21415113]     90%|█████████ | 90/100 [04:03<00:06,  1.50steps/s, loss=0.21419615]     91%|█████████ | 91/100 [04:04<00:06,  1.30steps/s, loss=0.21419615]     91%|█████████ | 91/100 [04:04<00:06,  1.30steps/s, loss=0.2143259]      92%|█████████▏| 92/100 [04:05<00:05,  1.34steps/s, loss=0.2143259]     92%|█████████▏| 92/100 [04:05<00:05,  1.34steps/s, loss=0.21435098]     93%|█████████▎| 93/100 [04:06<00:05,  1.39steps/s, loss=0.21435098]     93%|█████████▎| 93/100 [04:06<00:05,  1.39steps/s, loss=0.21426515]     94%|█████████▍| 94/100 [04:06<00:04,  1.42steps/s, loss=0.21426515]     94%|█████████▍| 94/100 [04:06<00:04,  1.42steps/s, loss=0.21405417]     95%|█████████▌| 95/100 [04:07<00:03,  1.47steps/s, loss=0.21405417]     95%|█████████▌| 95/100 [04:07<00:03,  1.47steps/s, loss=0.21415327]     96%|█████████▌| 96/100 [04:07<00:02,  1.55steps/s, loss=0.21415327]     96%|█████████▌| 96/100 [04:08<00:02,  1.55steps/s, loss=0.21423429]     97%|█████████▋| 97/100 [04:08<00:01,  1.65steps/s, loss=0.21423429]     97%|█████████▋| 97/100 [04:08<00:01,  1.65steps/s, loss=0.21432374]     98%|█████████▊| 98/100 [04:09<00:01,  1.69steps/s, loss=0.21432374]     98%|█████████▊| 98/100 [04:09<00:01,  1.69steps/s, loss=0.21422693]     99%|█████████▉| 99/100 [04:09<00:00,  1.76steps/s, loss=0.21422693]     99%|█████████▉| 99/100 [04:09<00:00,  1.76steps/s, loss=0.21424448]    100%|██████████| 100/100 [04:10<00:00,  1.54steps/s, loss=0.21424448]    100%|██████████| 100/100 [04:10<00:00,  2.50s/steps, loss=0.21424448]




.. GENERATED FROM PYTHON SOURCE LINES 255-259

.. image-sg:: /generated/autoexamples/GPU/images/mrinufft_learn_2d_sampling_pattern.gif
   :alt: example learn_samples
   :srcset: /generated/autoexamples/GPU/images/mrinufft_learn_2d_sampling_pattern.gif
   :class: sphx-glr-single-img

.. GENERATED FROM PYTHON SOURCE LINES 261-263

Trained trajectory
------------------

.. GENERATED FROM PYTHON SOURCE LINES 263-268

.. code-block:: Python

    model.eval()
    recon = model(mri_3D)
    plot_state(mri_3D, model.get_trajectory(True).detach().cpu().numpy(), recon, losses)
    plt.show()




.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_learn_straight_line_readouts_002.png
   :alt: MR Image, Reconstruction, Loss, Trajectory
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_learn_straight_line_readouts_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 269-284

References
==========

.. [Proj] N. Chauffert, P. Weiss, J. Kahn and P. Ciuciu, "A Projection Algorithm for
          Gradient Waveforms Design in Magnetic Resonance Imaging," in
          IEEE Transactions on Medical Imaging, vol. 35, no. 9, pp. 2026-2039, Sept. 2016,
          doi: 10.1109/TMI.2016.2544251.
.. [Sparks] G. R. Chaithya, P. Weiss, G. Daval-Frérot, A. Massire, A. Vignaud and P. Ciuciu,
          "Optimizing Full 3D SPARKLING Trajectories for High-Resolution Magnetic
          Resonance Imaging," in IEEE Transactions on Medical Imaging, vol. 41, no. 8,
          pp. 2105-2117, Aug. 2022, doi: 10.1109/TMI.2022.3157269.
.. [Projector] Chaithya GR, and Philippe Ciuciu. 2023. "Jointly Learning Non-Cartesian
          k-Space Trajectories and Reconstruction Networks for 2D and 3D MR Imaging
          through Projection" Bioengineering 10, no. 2: 158.
          https://doi.org/10.3390/bioengineering10020158


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (4 minutes 18.152 seconds)


.. _sphx_glr_download_generated_autoexamples_GPU_example_learn_straight_line_readouts.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/mind-inria/mri-nufft/gh-pages?urlpath=lab/tree/examples/generated/autoexamples/GPU/example_learn_straight_line_readouts.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: example_learn_straight_line_readouts.ipynb <example_learn_straight_line_readouts.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: example_learn_straight_line_readouts.py <example_learn_straight_line_readouts.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: example_learn_straight_line_readouts.zip <example_learn_straight_line_readouts.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
