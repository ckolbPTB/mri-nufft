
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "generated/autoexamples/GPU/example_learn_samples_multicoil.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_generated_autoexamples_GPU_example_learn_samples_multicoil.py>`
        to download the full example code. or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_generated_autoexamples_GPU_example_learn_samples_multicoil.py:


=========================================
Learn Sampling pattern for multi-coil MRI
=========================================

A small pytorch example to showcase learning k-space sampling patterns.
This example showcases the auto-diff capabilities of the NUFFT operator 
wrt to k-space trajectory in mri-nufft.

Briefly, in this example we try to learn the k-space samples :math:`\mathbf{K}` for the following cost function:

.. math::

    \mathbf{\hat{K}} =  arg \min_{\mathbf{K}} ||  \sum_{\ell=1}^LS_\ell^* \mathcal{F}_\mathbf{K}^* D_\mathbf{K} \mathcal{F}_\mathbf{K} x_\ell - \mathbf{x}_{sos} ||_2^2 
    
where :math:`S_\ell` is the sensitivity map for the :math:`\ell`-th coil, :math:`\mathcal{F}_\mathbf{K}` is the forward NUFFT operator and :math:`D_\mathbf{K}` is the density compensators for trajectory :math:`\mathbf{K}`,  :math:`\mathbf{x}_\ell` is the image for the :math:`\ell`-th coil, and :math:`\mathbf{x}_{sos} = \sqrt{\sum_{\ell=1}^L x_\ell^2}` is the sum-of-squares image as target image to be reconstructed.

In this example, the forward NUFFT operator :math:`\mathcal{F}_\mathbf{K}` is implemented with `model.operator` while the SENSE operator :math:`model.sense_op` models the term :math:`\mathbf{A} = \sum_{\ell=1}^LS_\ell^* \mathcal{F}_\mathbf{K}^* D_\mathbf{K}`.
For our data, we use a 2D slice of a 3D MRI image from the BrainWeb dataset, and the sensitivity maps are simulated using the `birdcage_maps` function from `sigpy.mri`.

.. note::
    To showcase the features of ``mri-nufft``, we use ``
    "cufinufft"`` backend for ``model.operator`` without density compensation and ``"gpunufft"`` backend for ``model.sense_op`` with density compensation. 
    
.. warning::
    This example only showcases the autodiff capabilities, the learned sampling pattern is not scanner compliant as the scanner gradients required to implement it violate the hardware constraints. In practice, a projection :math:`\Pi_\mathcal{Q}(\mathbf{K})` into the scanner constraints set :math:`\mathcal{Q}` is recommended (see [Proj]_). This is implemented in the proprietary SPARKLING package [Sparks]_. Users are encouraged to contact the authors if they want to use it.

.. GENERATED FROM PYTHON SOURCE LINES 30-34

.. colab-link::
   :needs_gpu: 1

   !pip install mri-nufft[gpunufft] cufinufft sigpy scikit-image

.. GENERATED FROM PYTHON SOURCE LINES 36-38

Imports
-------

.. GENERATED FROM PYTHON SOURCE LINES 38-53

.. code-block:: Python

    import time
    import joblib

    import brainweb_dl as bwdl
    import matplotlib.pyplot as plt
    import numpy as np
    import torch
    from tqdm import tqdm
    from PIL import Image, ImageSequence

    from mrinufft import get_operator
    from mrinufft.extras import get_smaps
    from mrinufft.trajectories import initialize_2D_radial
    from sigpy.mri import birdcage_maps








.. GENERATED FROM PYTHON SOURCE LINES 54-59

Setup a simple class to learn trajectory
----------------------------------------
.. note::
    While we are only learning the NUFFT operator, we still need the gradient `wrt_data=True` to have all the gradients computed correctly.
    See [Projector]_ for more details.

.. GENERATED FROM PYTHON SOURCE LINES 59-115

.. code-block:: Python



    class Model(torch.nn.Module):
        def __init__(self, inital_trajectory, n_coils, img_size=(256, 256)):
            super(Model, self).__init__()
            self.trajectory = torch.nn.Parameter(
                data=torch.Tensor(inital_trajectory),
                requires_grad=True,
            )
            sample_points = inital_trajectory.reshape(-1, inital_trajectory.shape[-1])
            # A simple acquisition model simulated with a forward NUFFT operator. We dont need density compensation here.
            # The trajectory is scaled by 2*pi for cufinufft backend.
            self.operator = get_operator("cufinufft", wrt_data=True, wrt_traj=True)(
                sample_points * 2 * np.pi,
                shape=img_size,
                n_coils=n_coils,
                squeeze_dims=False,
            )
            # A simple density compensated adjoint SENSE operator with sensitivity maps `smaps`.
            self.sense_op = get_operator("gpunufft", wrt_data=True, wrt_traj=True)(
                sample_points,
                shape=img_size,
                density=True,
                n_coils=n_coils,
                smaps=np.ones(
                    (n_coils, *img_size)
                ),  # Dummy smaps, this is updated in forward pass
                squeeze_dims=False,
            )
            self.img_size = img_size

        def forward(self, x):
            """Forward pass of the model."""
            # Update the trajectory in the NUFFT operator.
            # The trajectory is scaled by 2*pi for cufinufft backend.
            # Note that the re-computation of density compensation happens internally.
            self.operator.samples = self.trajectory.clone() * 2 * np.pi
            self.sense_op.samples = self.trajectory.clone()

            # Simulate the acquisition process
            kspace = self.operator.op(x)

            # Recompute the sensitivity maps for the updated trajectory.
            self.sense_op.smaps, _ = get_smaps("low_frequency")(
                self.trajectory.detach().numpy(),
                self.img_size,
                kspace.detach(),
                backend="gpunufft",
                density=self.sense_op.density,
                blurr_factor=20,
            )
            # Reconstruction using the sense operator
            adjoint = self.sense_op.adj_op(kspace).abs()
            return adjoint / torch.mean(adjoint)









.. GENERATED FROM PYTHON SOURCE LINES 116-118

Util function to plot the state of the model
--------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 118-139

.. code-block:: Python

    def plot_state(axs, mri_2D, traj, recon, loss=None, save_name=None):
        axs = axs.flatten()
        axs[0].imshow(np.abs(mri_2D), cmap="gray")
        axs[0].axis("off")
        axs[0].set_title("MR Image")
        axs[1].scatter(*traj.T, s=1)
        axs[1].set_title("Trajectory")
        axs[2].imshow(np.abs(recon[0][0].detach().cpu().numpy()), cmap="gray")
        axs[2].axis("off")
        axs[2].set_title("Reconstruction")
        if loss is not None:
            axs[3].plot(loss)
            axs[3].set_title("Loss")
            axs[3].grid("on")
        if save_name is not None:
            plt.savefig(save_name, bbox_inches="tight")
            plt.close()
        else:
            plt.show()









.. GENERATED FROM PYTHON SOURCE LINES 140-142

Setup model and optimizer
-------------------------

.. GENERATED FROM PYTHON SOURCE LINES 142-152

.. code-block:: Python

    n_coils = 6
    init_traj = initialize_2D_radial(32, 256).astype(np.float32).reshape(-1, 2)
    model = Model(init_traj, n_coils=n_coils, img_size=(256, 256))
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    schedulder = torch.optim.lr_scheduler.LinearLR(
        optimizer,
        start_factor=1,
        end_factor=0.1,
        total_iters=100,
    )




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /volatile/github-ci-mind-inria/gpu_runner/_work/_tool/Python/3.10.15/x64/lib/python3.10/site-packages/mrinufft/operators/interfaces/gpunufft.py:146: UserWarning: no pinning provided, pinning existing smaps now.
      warnings.warn("no pinning provided, pinning existing smaps now.")




.. GENERATED FROM PYTHON SOURCE LINES 153-155

Setup data
----------

.. GENERATED FROM PYTHON SOURCE LINES 155-164

.. code-block:: Python

    mri_2D = torch.from_numpy(np.flipud(bwdl.get_mri(4, "T1")[80, ...]).astype(np.float32))
    mri_2D = mri_2D / torch.mean(mri_2D)
    smaps_simulated = torch.from_numpy(birdcage_maps((n_coils, *mri_2D.shape)))
    mcmri_2D = mri_2D[None].to(torch.complex64) * smaps_simulated
    model.eval()
    recon = model(mcmri_2D)
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    plot_state(axs, mri_2D, model.trajectory.detach().cpu().numpy(), recon)




.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_001.png
   :alt: MR Image, Trajectory, Reconstruction
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 165-167

Start training loop
-------------------

.. GENERATED FROM PYTHON SOURCE LINES 167-215

.. code-block:: Python

    losses = []
    image_files = []
    model.train()

    with tqdm(range(100), unit="steps") as tqdms:
        for i in tqdms:
            out = model(mcmri_2D)
            loss = torch.nn.functional.mse_loss(out, mri_2D[None, None])
            numpy_loss = loss.detach().cpu().numpy()
            tqdms.set_postfix({"loss": numpy_loss})
            losses.append(numpy_loss)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            schedulder.step()
            with torch.no_grad():
                # Clamp the value of trajectory between [-0.5, 0.5]
                for param in model.parameters():
                    param.clamp_(-0.5, 0.5)
            # Generate images for gif
            hashed = joblib.hash((i, "learn_traj", time.time()))
            filename = "/tmp/" + f"{hashed}.png"
            plt.clf()
            fig, axs = plt.subplots(2, 2, figsize=(10, 10))
            plot_state(
                axs,
                mri_2D,
                model.trajectory.detach().cpu().numpy(),
                out,
                losses,
                save_name=filename,
            )
            image_files.append(filename)


    # Make a GIF of all images.
    imgs = [Image.open(img) for img in image_files]
    imgs[0].save(
        "mrinufft_learn_traj_mc.gif",
        save_all=True,
        append_images=imgs[1:],
        optimize=False,
        duration=2,
        loop=0,
    )

    # sphinx_gallery_thumbnail_path = 'generated/autoexamples/GPU/images/mrinufft_learn_traj_mc.gif'




.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_002.png
   :alt: example learn samples multicoil
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/100 [00:00<?, ?steps/s]      0%|          | 0/100 [00:00<?, ?steps/s, loss=0.15457293]/volatile/github-ci-mind-inria/gpu_runner/_work/_tool/Python/3.10.15/x64/lib/python3.10/site-packages/mrinufft/operators/autodiff.py:98: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:308.)
      grad_traj = torch.transpose(torch.sum(grad_traj, dim=1), 0, 1).to(
      1%|          | 1/100 [00:00<01:30,  1.09steps/s, loss=0.15457293]      1%|          | 1/100 [00:01<01:30,  1.09steps/s, loss=0.26573718]      2%|▏         | 2/100 [00:01<01:34,  1.03steps/s, loss=0.26573718]      2%|▏         | 2/100 [00:02<01:34,  1.03steps/s, loss=0.21166977]      3%|▎         | 3/100 [00:02<01:35,  1.02steps/s, loss=0.21166977]      3%|▎         | 3/100 [00:03<01:35,  1.02steps/s, loss=0.125733]        4%|▍         | 4/100 [00:04<01:39,  1.03s/steps, loss=0.125733]      4%|▍         | 4/100 [00:04<01:39,  1.03s/steps, loss=0.10511179]      5%|▌         | 5/100 [00:04<01:33,  1.02steps/s, loss=0.10511179]      5%|▌         | 5/100 [00:05<01:33,  1.02steps/s, loss=0.09466474]      6%|▌         | 6/100 [00:05<01:29,  1.06steps/s, loss=0.09466474]      6%|▌         | 6/100 [00:05<01:29,  1.06steps/s, loss=0.08185789]      7%|▋         | 7/100 [00:06<01:25,  1.08steps/s, loss=0.08185789]      7%|▋         | 7/100 [00:06<01:25,  1.08steps/s, loss=0.08021871]      8%|▊         | 8/100 [00:07<01:22,  1.12steps/s, loss=0.08021871]      8%|▊         | 8/100 [00:07<01:22,  1.12steps/s, loss=0.07346457]      9%|▉         | 9/100 [00:08<01:20,  1.13steps/s, loss=0.07346457]      9%|▉         | 9/100 [00:08<01:20,  1.13steps/s, loss=0.06796092]     10%|█         | 10/100 [00:09<01:23,  1.07steps/s, loss=0.06796092]     10%|█         | 10/100 [00:09<01:23,  1.07steps/s, loss=0.06145895]     11%|█         | 11/100 [00:10<01:23,  1.07steps/s, loss=0.06145895]     11%|█         | 11/100 [00:10<01:23,  1.07steps/s, loss=0.05936887]     12%|█▏        | 12/100 [00:11<01:22,  1.07steps/s, loss=0.05936887]     12%|█▏        | 12/100 [00:11<01:22,  1.07steps/s, loss=0.05722914]     13%|█▎        | 13/100 [00:12<01:29,  1.02s/steps, loss=0.05722914]     13%|█▎        | 13/100 [00:12<01:29,  1.02s/steps, loss=0.05439534]     14%|█▍        | 14/100 [00:13<01:25,  1.01steps/s, loss=0.05439534]     14%|█▍        | 14/100 [00:13<01:25,  1.01steps/s, loss=0.052435596]     15%|█▌        | 15/100 [00:14<01:21,  1.04steps/s, loss=0.052435596]     15%|█▌        | 15/100 [00:14<01:21,  1.04steps/s, loss=0.050774954]     16%|█▌        | 16/100 [00:15<01:17,  1.09steps/s, loss=0.050774954]     16%|█▌        | 16/100 [00:15<01:17,  1.09steps/s, loss=0.04882226]      17%|█▋        | 17/100 [00:15<01:13,  1.13steps/s, loss=0.04882226]     17%|█▋        | 17/100 [00:16<01:13,  1.13steps/s, loss=0.046842575]     18%|█▊        | 18/100 [00:16<01:11,  1.14steps/s, loss=0.046842575]     18%|█▊        | 18/100 [00:17<01:11,  1.14steps/s, loss=0.044623334]     19%|█▉        | 19/100 [00:17<01:10,  1.15steps/s, loss=0.044623334]     19%|█▉        | 19/100 [00:17<01:10,  1.15steps/s, loss=0.0433101]       20%|██        | 20/100 [00:18<01:09,  1.14steps/s, loss=0.0433101]     20%|██        | 20/100 [00:18<01:09,  1.14steps/s, loss=0.042934965]     21%|██        | 21/100 [00:19<01:10,  1.12steps/s, loss=0.042934965]     21%|██        | 21/100 [00:19<01:10,  1.12steps/s, loss=0.041302003]     22%|██▏       | 22/100 [00:20<01:10,  1.11steps/s, loss=0.041302003]     22%|██▏       | 22/100 [00:20<01:10,  1.11steps/s, loss=0.041466348]     23%|██▎       | 23/100 [00:21<01:15,  1.02steps/s, loss=0.041466348]     23%|██▎       | 23/100 [00:21<01:15,  1.02steps/s, loss=0.04069598]      24%|██▍       | 24/100 [00:22<01:13,  1.04steps/s, loss=0.04069598]     24%|██▍       | 24/100 [00:22<01:13,  1.04steps/s, loss=0.039058067]     25%|██▌       | 25/100 [00:23<01:11,  1.05steps/s, loss=0.039058067]     25%|██▌       | 25/100 [00:23<01:11,  1.05steps/s, loss=0.03834138]      26%|██▌       | 26/100 [00:24<01:09,  1.07steps/s, loss=0.03834138]     26%|██▌       | 26/100 [00:24<01:09,  1.07steps/s, loss=0.038209487]     27%|██▋       | 27/100 [00:25<01:08,  1.07steps/s, loss=0.038209487]     27%|██▋       | 27/100 [00:25<01:08,  1.07steps/s, loss=0.0363913]       28%|██▊       | 28/100 [00:26<01:07,  1.07steps/s, loss=0.0363913]     28%|██▊       | 28/100 [00:26<01:07,  1.07steps/s, loss=0.0357584]     29%|██▉       | 29/100 [00:27<01:05,  1.08steps/s, loss=0.0357584]     29%|██▉       | 29/100 [00:27<01:05,  1.08steps/s, loss=0.036147498]     30%|███       | 30/100 [00:27<01:04,  1.09steps/s, loss=0.036147498]     30%|███       | 30/100 [00:28<01:04,  1.09steps/s, loss=0.035395607]     31%|███       | 31/100 [00:28<01:02,  1.11steps/s, loss=0.035395607]     31%|███       | 31/100 [00:29<01:02,  1.11steps/s, loss=0.0342028]       32%|███▏      | 32/100 [00:30<01:08,  1.01s/steps, loss=0.0342028]     32%|███▏      | 32/100 [00:30<01:08,  1.01s/steps, loss=0.0338768]     33%|███▎      | 33/100 [00:31<01:06,  1.01steps/s, loss=0.0338768]     33%|███▎      | 33/100 [00:31<01:06,  1.01steps/s, loss=0.034201697]     34%|███▍      | 34/100 [00:31<01:03,  1.04steps/s, loss=0.034201697]     34%|███▍      | 34/100 [00:32<01:03,  1.04steps/s, loss=0.034732934]     35%|███▌      | 35/100 [00:32<01:00,  1.08steps/s, loss=0.034732934]     35%|███▌      | 35/100 [00:33<01:00,  1.08steps/s, loss=0.03310102]      36%|███▌      | 36/100 [00:33<00:57,  1.12steps/s, loss=0.03310102]     36%|███▌      | 36/100 [00:33<00:57,  1.12steps/s, loss=0.03309852]     37%|███▋      | 37/100 [00:34<00:55,  1.13steps/s, loss=0.03309852]     37%|███▋      | 37/100 [00:34<00:55,  1.13steps/s, loss=0.032998215]     38%|███▊      | 38/100 [00:35<00:53,  1.15steps/s, loss=0.032998215]     38%|███▊      | 38/100 [00:35<00:53,  1.15steps/s, loss=0.032361213]     39%|███▉      | 39/100 [00:36<00:52,  1.17steps/s, loss=0.032361213]     39%|███▉      | 39/100 [00:36<00:52,  1.17steps/s, loss=0.03185252]      40%|████      | 40/100 [00:36<00:50,  1.20steps/s, loss=0.03185252]     40%|████      | 40/100 [00:37<00:50,  1.20steps/s, loss=0.031550664]     41%|████      | 41/100 [00:38<00:56,  1.04steps/s, loss=0.031550664]     41%|████      | 41/100 [00:38<00:56,  1.04steps/s, loss=0.0313185]       42%|████▏     | 42/100 [00:39<00:55,  1.05steps/s, loss=0.0313185]     42%|████▏     | 42/100 [00:39<00:55,  1.05steps/s, loss=0.031134149]     43%|████▎     | 43/100 [00:39<00:52,  1.09steps/s, loss=0.031134149]     43%|████▎     | 43/100 [00:40<00:52,  1.09steps/s, loss=0.031634785]     44%|████▍     | 44/100 [00:40<00:50,  1.12steps/s, loss=0.031634785]     44%|████▍     | 44/100 [00:41<00:50,  1.12steps/s, loss=0.030577032]     45%|████▌     | 45/100 [00:41<00:48,  1.13steps/s, loss=0.030577032]     45%|████▌     | 45/100 [00:41<00:48,  1.13steps/s, loss=0.029810922]     46%|████▌     | 46/100 [00:42<00:49,  1.10steps/s, loss=0.029810922]     46%|████▌     | 46/100 [00:42<00:49,  1.10steps/s, loss=0.030318625]     47%|████▋     | 47/100 [00:43<00:47,  1.12steps/s, loss=0.030318625]     47%|████▋     | 47/100 [00:43<00:47,  1.12steps/s, loss=0.03003709]      48%|████▊     | 48/100 [00:44<00:45,  1.15steps/s, loss=0.03003709]     48%|████▊     | 48/100 [00:44<00:45,  1.15steps/s, loss=0.030143943]     49%|████▉     | 49/100 [00:45<00:44,  1.16steps/s, loss=0.030143943]     49%|████▉     | 49/100 [00:45<00:44,  1.16steps/s, loss=0.031042164]     50%|█████     | 50/100 [00:46<00:42,  1.17steps/s, loss=0.031042164]     50%|█████     | 50/100 [00:46<00:42,  1.17steps/s, loss=0.03056602]      51%|█████     | 51/100 [00:47<00:46,  1.06steps/s, loss=0.03056602]     51%|█████     | 51/100 [00:47<00:46,  1.06steps/s, loss=0.030138537]     52%|█████▏    | 52/100 [00:48<00:44,  1.08steps/s, loss=0.030138537]     52%|█████▏    | 52/100 [00:48<00:44,  1.08steps/s, loss=0.029323127]     53%|█████▎    | 53/100 [00:48<00:42,  1.11steps/s, loss=0.029323127]     53%|█████▎    | 53/100 [00:49<00:42,  1.11steps/s, loss=0.028532073]     54%|█████▍    | 54/100 [00:49<00:40,  1.14steps/s, loss=0.028532073]     54%|█████▍    | 54/100 [00:49<00:40,  1.14steps/s, loss=0.028901253]     55%|█████▌    | 55/100 [00:50<00:39,  1.15steps/s, loss=0.028901253]     55%|█████▌    | 55/100 [00:50<00:39,  1.15steps/s, loss=0.029972903]     56%|█████▌    | 56/100 [00:51<00:39,  1.11steps/s, loss=0.029972903]     56%|█████▌    | 56/100 [00:51<00:39,  1.11steps/s, loss=0.029454967]     57%|█████▋    | 57/100 [00:52<00:39,  1.09steps/s, loss=0.029454967]     57%|█████▋    | 57/100 [00:52<00:39,  1.09steps/s, loss=0.029619996]     58%|█████▊    | 58/100 [00:53<00:37,  1.11steps/s, loss=0.029619996]     58%|█████▊    | 58/100 [00:53<00:37,  1.11steps/s, loss=0.030097226]     59%|█████▉    | 59/100 [00:54<00:37,  1.09steps/s, loss=0.030097226]     59%|█████▉    | 59/100 [00:54<00:37,  1.09steps/s, loss=0.030045278]     60%|██████    | 60/100 [00:55<00:40,  1.02s/steps, loss=0.030045278]     60%|██████    | 60/100 [00:55<00:40,  1.02s/steps, loss=0.029199308]     61%|██████    | 61/100 [00:56<00:38,  1.01steps/s, loss=0.029199308]     61%|██████    | 61/100 [00:56<00:38,  1.01steps/s, loss=0.028436992]     62%|██████▏   | 62/100 [00:57<00:35,  1.07steps/s, loss=0.028436992]     62%|██████▏   | 62/100 [00:57<00:35,  1.07steps/s, loss=0.028617851]     63%|██████▎   | 63/100 [00:58<00:33,  1.09steps/s, loss=0.028617851]     63%|██████▎   | 63/100 [00:58<00:33,  1.09steps/s, loss=0.028997835]     64%|██████▍   | 64/100 [00:59<00:32,  1.10steps/s, loss=0.028997835]     64%|██████▍   | 64/100 [00:59<00:32,  1.10steps/s, loss=0.028244805]     65%|██████▌   | 65/100 [00:59<00:30,  1.13steps/s, loss=0.028244805]     65%|██████▌   | 65/100 [01:00<00:30,  1.13steps/s, loss=0.027369462]     66%|██████▌   | 66/100 [01:00<00:29,  1.14steps/s, loss=0.027369462]     66%|██████▌   | 66/100 [01:00<00:29,  1.14steps/s, loss=0.027351819]     67%|██████▋   | 67/100 [01:01<00:28,  1.14steps/s, loss=0.027351819]     67%|██████▋   | 67/100 [01:01<00:28,  1.14steps/s, loss=0.027299326]     68%|██████▊   | 68/100 [01:02<00:27,  1.16steps/s, loss=0.027299326]     68%|██████▊   | 68/100 [01:02<00:27,  1.16steps/s, loss=0.02762074]      69%|██████▉   | 69/100 [01:03<00:26,  1.17steps/s, loss=0.02762074]     69%|██████▉   | 69/100 [01:03<00:26,  1.17steps/s, loss=0.027436774]     70%|███████   | 70/100 [01:04<00:28,  1.04steps/s, loss=0.027436774]     70%|███████   | 70/100 [01:04<00:28,  1.04steps/s, loss=0.027205668]     71%|███████   | 71/100 [01:05<00:26,  1.08steps/s, loss=0.027205668]     71%|███████   | 71/100 [01:05<00:26,  1.08steps/s, loss=0.027364502]     72%|███████▏  | 72/100 [01:06<00:25,  1.10steps/s, loss=0.027364502]     72%|███████▏  | 72/100 [01:06<00:25,  1.10steps/s, loss=0.027390284]     73%|███████▎  | 73/100 [01:07<00:25,  1.06steps/s, loss=0.027390284]     73%|███████▎  | 73/100 [01:07<00:25,  1.06steps/s, loss=0.027053792]     74%|███████▍  | 74/100 [01:08<00:23,  1.10steps/s, loss=0.027053792]     74%|███████▍  | 74/100 [01:08<00:23,  1.10steps/s, loss=0.026888346]     75%|███████▌  | 75/100 [01:08<00:22,  1.13steps/s, loss=0.026888346]     75%|███████▌  | 75/100 [01:09<00:22,  1.13steps/s, loss=0.027139112]     76%|███████▌  | 76/100 [01:09<00:20,  1.14steps/s, loss=0.027139112]     76%|███████▌  | 76/100 [01:09<00:20,  1.14steps/s, loss=0.027753428]     77%|███████▋  | 77/100 [01:10<00:21,  1.09steps/s, loss=0.027753428]     77%|███████▋  | 77/100 [01:10<00:21,  1.09steps/s, loss=0.028371856]     78%|███████▊  | 78/100 [01:11<00:19,  1.13steps/s, loss=0.028371856]     78%|███████▊  | 78/100 [01:11<00:19,  1.13steps/s, loss=0.026950091]     79%|███████▉  | 79/100 [01:12<00:19,  1.09steps/s, loss=0.026950091]     79%|███████▉  | 79/100 [01:12<00:19,  1.09steps/s, loss=0.027361987]     80%|████████  | 80/100 [01:13<00:17,  1.16steps/s, loss=0.027361987]     80%|████████  | 80/100 [01:13<00:17,  1.16steps/s, loss=0.028015468]     81%|████████  | 81/100 [01:14<00:16,  1.19steps/s, loss=0.028015468]     81%|████████  | 81/100 [01:14<00:16,  1.19steps/s, loss=0.027880266]     82%|████████▏ | 82/100 [01:14<00:14,  1.23steps/s, loss=0.027880266]     82%|████████▏ | 82/100 [01:14<00:14,  1.23steps/s, loss=0.026904777]     83%|████████▎ | 83/100 [01:15<00:13,  1.28steps/s, loss=0.026904777]     83%|████████▎ | 83/100 [01:15<00:13,  1.28steps/s, loss=0.026652459]     84%|████████▍ | 84/100 [01:16<00:12,  1.30steps/s, loss=0.026652459]     84%|████████▍ | 84/100 [01:16<00:12,  1.30steps/s, loss=0.02648997]      85%|████████▌ | 85/100 [01:16<00:11,  1.32steps/s, loss=0.02648997]     85%|████████▌ | 85/100 [01:17<00:11,  1.32steps/s, loss=0.026704844]     86%|████████▌ | 86/100 [01:17<00:10,  1.32steps/s, loss=0.026704844]     86%|████████▌ | 86/100 [01:17<00:10,  1.32steps/s, loss=0.02733936]      87%|████████▋ | 87/100 [01:18<00:09,  1.33steps/s, loss=0.02733936]     87%|████████▋ | 87/100 [01:18<00:09,  1.33steps/s, loss=0.02714577]     88%|████████▊ | 88/100 [01:19<00:08,  1.34steps/s, loss=0.02714577]     88%|████████▊ | 88/100 [01:19<00:08,  1.34steps/s, loss=0.027066737]     89%|████████▉ | 89/100 [01:20<00:09,  1.21steps/s, loss=0.027066737]     89%|████████▉ | 89/100 [01:20<00:09,  1.21steps/s, loss=0.027018674]     90%|█████████ | 90/100 [01:20<00:08,  1.24steps/s, loss=0.027018674]     90%|█████████ | 90/100 [01:21<00:08,  1.24steps/s, loss=0.026945895]     91%|█████████ | 91/100 [01:21<00:07,  1.27steps/s, loss=0.026945895]     91%|█████████ | 91/100 [01:21<00:07,  1.27steps/s, loss=0.026624015]     92%|█████████▏| 92/100 [01:22<00:06,  1.30steps/s, loss=0.026624015]     92%|█████████▏| 92/100 [01:22<00:06,  1.30steps/s, loss=0.026165213]     93%|█████████▎| 93/100 [01:23<00:05,  1.32steps/s, loss=0.026165213]     93%|█████████▎| 93/100 [01:23<00:05,  1.32steps/s, loss=0.026029501]     94%|█████████▍| 94/100 [01:23<00:04,  1.34steps/s, loss=0.026029501]     94%|█████████▍| 94/100 [01:24<00:04,  1.34steps/s, loss=0.025878424]     95%|█████████▌| 95/100 [01:24<00:03,  1.34steps/s, loss=0.025878424]     95%|█████████▌| 95/100 [01:24<00:03,  1.34steps/s, loss=0.025997244]     96%|█████████▌| 96/100 [01:25<00:02,  1.35steps/s, loss=0.025997244]     96%|█████████▌| 96/100 [01:25<00:02,  1.35steps/s, loss=0.026143089]     97%|█████████▋| 97/100 [01:26<00:02,  1.35steps/s, loss=0.026143089]     97%|█████████▋| 97/100 [01:26<00:02,  1.35steps/s, loss=0.02586526]      98%|█████████▊| 98/100 [01:27<00:01,  1.21steps/s, loss=0.02586526]     98%|█████████▊| 98/100 [01:27<00:01,  1.21steps/s, loss=0.025637783]     99%|█████████▉| 99/100 [01:27<00:00,  1.25steps/s, loss=0.025637783]     99%|█████████▉| 99/100 [01:28<00:00,  1.25steps/s, loss=0.025502142]    100%|██████████| 100/100 [01:28<00:00,  1.28steps/s, loss=0.025502142]    100%|██████████| 100/100 [01:28<00:00,  1.13steps/s, loss=0.025502142]




.. GENERATED FROM PYTHON SOURCE LINES 244-248

.. image-sg:: /generated/autoexamples/GPU/images/mrinufft_learn_traj_mc.gif
   :alt: example learn_samples
   :srcset: /generated/autoexamples/GPU/images/mrinufft_learn_traj_mc.gif
   :class: sphx-glr-single-img

.. GENERATED FROM PYTHON SOURCE LINES 250-252

Trained trajectory
------------------

.. GENERATED FROM PYTHON SOURCE LINES 252-259

.. code-block:: Python

    model.eval()
    recon = model(mcmri_2D)
    fig, axs = plt.subplots(2, 2, figsize=(10, 10))
    plot_state(axs, mri_2D, model.trajectory.detach().cpu().numpy(), recon, losses)
    plt.show()





.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_003.png
   :alt: MR Image, Trajectory, Reconstruction, Loss
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 260-275

References
==========

.. [Proj] N. Chauffert, P. Weiss, J. Kahn and P. Ciuciu, "A Projection Algorithm for
          Gradient Waveforms Design in Magnetic Resonance Imaging," in
          IEEE Transactions on Medical Imaging, vol. 35, no. 9, pp. 2026-2039, Sept. 2016,
          doi: 10.1109/TMI.2016.2544251.
.. [Sparks] G. R. Chaithya, P. Weiss, G. Daval-Frérot, A. Massire, A. Vignaud and P. Ciuciu,
          "Optimizing Full 3D SPARKLING Trajectories for High-Resolution Magnetic
          Resonance Imaging," in IEEE Transactions on Medical Imaging, vol. 41, no. 8,
          pp. 2105-2117, Aug. 2022, doi: 10.1109/TMI.2022.3157269.
.. [Projector] Chaithya GR, and Philippe Ciuciu. 2023. "Jointly Learning Non-Cartesian
          k-Space Trajectories and Reconstruction Networks for 2D and 3D MR Imaging
          through Projection" Bioengineering 10, no. 2: 158.
          https://doi.org/10.3390/bioengineering10020158


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 36.476 seconds)


.. _sphx_glr_download_generated_autoexamples_GPU_example_learn_samples_multicoil.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/mind-inria/mri-nufft/gh-pages?urlpath=lab/tree/examples/generated/autoexamples/GPU/example_learn_samples_multicoil.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: example_learn_samples_multicoil.ipynb <example_learn_samples_multicoil.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: example_learn_samples_multicoil.py <example_learn_samples_multicoil.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: example_learn_samples_multicoil.zip <example_learn_samples_multicoil.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
