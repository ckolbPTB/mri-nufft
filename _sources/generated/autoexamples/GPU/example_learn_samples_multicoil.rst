
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "generated/autoexamples/GPU/example_learn_samples_multicoil.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_generated_autoexamples_GPU_example_learn_samples_multicoil.py>`
        to download the full example code. or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_generated_autoexamples_GPU_example_learn_samples_multicoil.py:


=========================================
Learn Sampling pattern for multi-coil MRI
=========================================

A small pytorch example to showcase learning k-space sampling patterns.
This example showcases the auto-diff capabilities of the NUFFT operator 
wrt to k-space trajectory in mri-nufft.

Briefly, in this example we try to learn the k-space samples :math:`\mathbf{K}` for the following cost function:

.. math::

    \mathbf{\hat{K}} =  arg \min_{\mathbf{K}} ||  \sum_{\ell=1}^LS_\ell^* \mathcal{F}_\mathbf{K}^* D_\mathbf{K} \mathcal{F}_\mathbf{K} x_\ell - \mathbf{x}_{sos} ||_2^2 
    
where :math:`S_\ell` is the sensitivity map for the :math:`\ell`-th coil, :math:`\mathcal{F}_\mathbf{K}` is the forward NUFFT operator and :math:`D_\mathbf{K}` is the density compensators for trajectory :math:`\mathbf{K}`,  :math:`\mathbf{x}_\ell` is the image for the :math:`\ell`-th coil, and :math:`\mathbf{x}_{sos} = \sqrt{\sum_{\ell=1}^L x_\ell^2}` is the sum-of-squares image as target image to be reconstructed.

In this example, the forward NUFFT operator :math:`\mathcal{F}_\mathbf{K}` is implemented with `model.operator` while the SENSE operator :math:`model.sense_op` models the term :math:`\mathbf{A} = \sum_{\ell=1}^LS_\ell^* \mathcal{F}_\mathbf{K}^* D_\mathbf{K}`.
For our data, we use a 2D slice of a 3D MRI image from the BrainWeb dataset, and the sensitivity maps are simulated using the `birdcage_maps` function from `sigpy.mri`.

.. note::
    To showcase the features of ``mri-nufft``, we use ``
    "cufinufft"`` backend for ``model.operator`` without density compensation and ``"gpunufft"`` backend for ``model.sense_op`` with density compensation. 
    
.. warning::
    This example only showcases the autodiff capabilities, the learned sampling pattern is not scanner compliant as the scanner gradients required to implement it violate the hardware constraints. In practice, a projection :math:`\Pi_\mathcal{Q}(\mathbf{K})` into the scanner constraints set :math:`\mathcal{Q}` is recommended (see [Proj]_). This is implemented in the proprietary SPARKLING package [Sparks]_. Users are encouraged to contact the authors if they want to use it.

.. GENERATED FROM PYTHON SOURCE LINES 30-34

.. colab-link::
   :needs_gpu: 1

   !pip install mri-nufft[gpunufft] cufinufft sigpy scikit-image

.. GENERATED FROM PYTHON SOURCE LINES 36-38

Imports
-------

.. GENERATED FROM PYTHON SOURCE LINES 38-53

.. code-block:: Python

    import time
    import joblib

    import brainweb_dl as bwdl
    import matplotlib.pyplot as plt
    import numpy as np
    import torch
    from tqdm import tqdm
    from PIL import Image, ImageSequence

    from mrinufft import get_operator
    from mrinufft.extras import get_smaps
    from mrinufft.trajectories import initialize_2D_radial
    from sigpy.mri import birdcage_maps








.. GENERATED FROM PYTHON SOURCE LINES 54-59

Setup a simple class to learn trajectory
----------------------------------------
.. note::
    While we are only learning the NUFFT operator, we still need the gradient `wrt_data=True` to have all the gradients computed correctly.
    See [Projector]_ for more details.

.. GENERATED FROM PYTHON SOURCE LINES 59-115

.. code-block:: Python



    class Model(torch.nn.Module):
        def __init__(self, inital_trajectory, n_coils, img_size=(256, 256)):
            super(Model, self).__init__()
            self.trajectory = torch.nn.Parameter(
                data=torch.Tensor(inital_trajectory),
                requires_grad=True,
            )
            sample_points = inital_trajectory.reshape(-1, inital_trajectory.shape[-1])
            # A simple acquisition model simulated with a forward NUFFT operator. We dont need density compensation here.
            # The trajectory is scaled by 2*pi for cufinufft backend.
            self.operator = get_operator("cufinufft", wrt_data=True, wrt_traj=True)(
                sample_points * 2 * np.pi,
                shape=img_size,
                n_coils=n_coils,
                squeeze_dims=False,
            )
            # A simple density compensated adjoint SENSE operator with sensitivity maps `smaps`.
            self.sense_op = get_operator("gpunufft", wrt_data=True, wrt_traj=True)(
                sample_points,
                shape=img_size,
                density=True,
                n_coils=n_coils,
                smaps=np.ones(
                    (n_coils, *img_size)
                ),  # Dummy smaps, this is updated in forward pass
                squeeze_dims=False,
            )
            self.img_size = img_size

        def forward(self, x):
            """Forward pass of the model."""
            # Update the trajectory in the NUFFT operator.
            # The trajectory is scaled by 2*pi for cufinufft backend.
            # Note that the re-computation of density compensation happens internally.
            self.operator.samples = self.trajectory.clone() * 2 * np.pi
            self.sense_op.samples = self.trajectory.clone()

            # Simulate the acquisition process
            kspace = self.operator.op(x)

            # Recompute the sensitivity maps for the updated trajectory.
            self.sense_op.smaps, _ = get_smaps("low_frequency")(
                self.trajectory.detach().numpy(),
                self.img_size,
                kspace.detach(),
                backend="gpunufft",
                density=self.sense_op.density,
                blurr_factor=20,
            )
            # Reconstruction using the sense operator
            adjoint = self.sense_op.adj_op(kspace).abs()
            return adjoint / torch.mean(adjoint)









.. GENERATED FROM PYTHON SOURCE LINES 116-118

Util function to plot the state of the model
--------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 118-139

.. code-block:: Python

    def plot_state(axs, mri_2D, traj, recon, loss=None, save_name=None):
        axs = axs.flatten()
        axs[0].imshow(np.abs(mri_2D), cmap="gray")
        axs[0].axis("off")
        axs[0].set_title("MR Image")
        axs[1].scatter(*traj.T, s=1)
        axs[1].set_title("Trajectory")
        axs[2].imshow(np.abs(recon[0][0].detach().cpu().numpy()), cmap="gray")
        axs[2].axis("off")
        axs[2].set_title("Reconstruction")
        if loss is not None:
            axs[3].plot(loss)
            axs[3].set_title("Loss")
            axs[3].grid("on")
        if save_name is not None:
            plt.savefig(save_name, bbox_inches="tight")
            plt.close()
        else:
            plt.show()









.. GENERATED FROM PYTHON SOURCE LINES 140-142

Setup model and optimizer
-------------------------

.. GENERATED FROM PYTHON SOURCE LINES 142-152

.. code-block:: Python

    n_coils = 6
    init_traj = initialize_2D_radial(32, 256).astype(np.float32).reshape(-1, 2)
    model = Model(init_traj, n_coils=n_coils, img_size=(256, 256))
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    schedulder = torch.optim.lr_scheduler.LinearLR(
        optimizer,
        start_factor=1,
        end_factor=0.1,
        total_iters=100,
    )




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /volatile/github-ci-mind-inria/gpu_runner/_work/_tool/Python/3.10.15/x64/lib/python3.10/site-packages/mrinufft/operators/interfaces/gpunufft.py:146: UserWarning: no pinning provided, pinning existing smaps now.
      warnings.warn("no pinning provided, pinning existing smaps now.")




.. GENERATED FROM PYTHON SOURCE LINES 153-155

Setup data
----------

.. GENERATED FROM PYTHON SOURCE LINES 155-164

.. code-block:: Python

    mri_2D = torch.from_numpy(np.flipud(bwdl.get_mri(4, "T1")[80, ...]).astype(np.float32))
    mri_2D = mri_2D / torch.mean(mri_2D)
    smaps_simulated = torch.from_numpy(birdcage_maps((n_coils, *mri_2D.shape)))
    mcmri_2D = mri_2D[None].to(torch.complex64) * smaps_simulated
    model.eval()
    recon = model(mcmri_2D)
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    plot_state(axs, mri_2D, model.trajectory.detach().cpu().numpy(), recon)




.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_001.png
   :alt: MR Image, Trajectory, Reconstruction
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 165-167

Start training loop
-------------------

.. GENERATED FROM PYTHON SOURCE LINES 167-215

.. code-block:: Python

    losses = []
    image_files = []
    model.train()

    with tqdm(range(100), unit="steps") as tqdms:
        for i in tqdms:
            out = model(mcmri_2D)
            loss = torch.nn.functional.mse_loss(out, mri_2D[None, None])
            numpy_loss = loss.detach().cpu().numpy()
            tqdms.set_postfix({"loss": numpy_loss})
            losses.append(numpy_loss)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            schedulder.step()
            with torch.no_grad():
                # Clamp the value of trajectory between [-0.5, 0.5]
                for param in model.parameters():
                    param.clamp_(-0.5, 0.5)
            # Generate images for gif
            hashed = joblib.hash((i, "learn_traj", time.time()))
            filename = "/tmp/" + f"{hashed}.png"
            plt.clf()
            fig, axs = plt.subplots(2, 2, figsize=(10, 10))
            plot_state(
                axs,
                mri_2D,
                model.trajectory.detach().cpu().numpy(),
                out,
                losses,
                save_name=filename,
            )
            image_files.append(filename)


    # Make a GIF of all images.
    imgs = [Image.open(img) for img in image_files]
    imgs[0].save(
        "mrinufft_learn_traj_mc.gif",
        save_all=True,
        append_images=imgs[1:],
        optimize=False,
        duration=2,
        loop=0,
    )

    # sphinx_gallery_thumbnail_path = 'generated/autoexamples/GPU/images/mrinufft_learn_traj_mc.gif'




.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_002.png
   :alt: example learn samples multicoil
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/100 [00:00<?, ?steps/s]      0%|          | 0/100 [00:00<?, ?steps/s, loss=0.1546382]/volatile/github-ci-mind-inria/gpu_runner/_work/_tool/Python/3.10.15/x64/lib/python3.10/site-packages/mrinufft/operators/autodiff.py:98: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:308.)
      grad_traj = torch.transpose(torch.sum(grad_traj, dim=1), 0, 1).to(
      1%|          | 1/100 [00:00<01:18,  1.26steps/s, loss=0.1546382]      1%|          | 1/100 [00:00<01:18,  1.26steps/s, loss=0.2720515]      2%|▏         | 2/100 [00:01<01:16,  1.28steps/s, loss=0.2720515]      2%|▏         | 2/100 [00:01<01:16,  1.28steps/s, loss=0.21600187]      3%|▎         | 3/100 [00:02<01:16,  1.26steps/s, loss=0.21600187]      3%|▎         | 3/100 [00:02<01:16,  1.26steps/s, loss=0.123969086]      4%|▍         | 4/100 [00:03<01:25,  1.13steps/s, loss=0.123969086]      4%|▍         | 4/100 [00:03<01:25,  1.13steps/s, loss=0.1041124]        5%|▌         | 5/100 [00:04<01:21,  1.17steps/s, loss=0.1041124]      5%|▌         | 5/100 [00:04<01:21,  1.17steps/s, loss=0.09544499]      6%|▌         | 6/100 [00:05<01:19,  1.19steps/s, loss=0.09544499]      6%|▌         | 6/100 [00:05<01:19,  1.19steps/s, loss=0.078418106]      7%|▋         | 7/100 [00:05<01:18,  1.18steps/s, loss=0.078418106]      7%|▋         | 7/100 [00:06<01:18,  1.18steps/s, loss=0.08313595]       8%|▊         | 8/100 [00:06<01:17,  1.19steps/s, loss=0.08313595]      8%|▊         | 8/100 [00:06<01:17,  1.19steps/s, loss=0.076408505]      9%|▉         | 9/100 [00:07<01:19,  1.15steps/s, loss=0.076408505]      9%|▉         | 9/100 [00:07<01:19,  1.15steps/s, loss=0.0671445]       10%|█         | 10/100 [00:08<01:18,  1.15steps/s, loss=0.0671445]     10%|█         | 10/100 [00:08<01:18,  1.15steps/s, loss=0.064115]      11%|█         | 11/100 [00:09<01:18,  1.14steps/s, loss=0.064115]     11%|█         | 11/100 [00:09<01:18,  1.14steps/s, loss=0.059731152]     12%|█▏        | 12/100 [00:10<01:18,  1.12steps/s, loss=0.059731152]     12%|█▏        | 12/100 [00:10<01:18,  1.12steps/s, loss=0.057512626]     13%|█▎        | 13/100 [00:11<01:25,  1.02steps/s, loss=0.057512626]     13%|█▎        | 13/100 [00:11<01:25,  1.02steps/s, loss=0.05647386]      14%|█▍        | 14/100 [00:12<01:23,  1.03steps/s, loss=0.05647386]     14%|█▍        | 14/100 [00:12<01:23,  1.03steps/s, loss=0.055035777]     15%|█▌        | 15/100 [00:13<01:24,  1.01steps/s, loss=0.055035777]     15%|█▌        | 15/100 [00:13<01:24,  1.01steps/s, loss=0.051434368]     16%|█▌        | 16/100 [00:14<01:17,  1.09steps/s, loss=0.051434368]     16%|█▌        | 16/100 [00:14<01:17,  1.09steps/s, loss=0.049533654]     17%|█▋        | 17/100 [00:15<01:12,  1.14steps/s, loss=0.049533654]     17%|█▋        | 17/100 [00:15<01:12,  1.14steps/s, loss=0.04867959]      18%|█▊        | 18/100 [00:15<01:10,  1.16steps/s, loss=0.04867959]     18%|█▊        | 18/100 [00:16<01:10,  1.16steps/s, loss=0.047209583]     19%|█▉        | 19/100 [00:16<01:09,  1.16steps/s, loss=0.047209583]     19%|█▉        | 19/100 [00:16<01:09,  1.16steps/s, loss=0.045264155]     20%|██        | 20/100 [00:17<01:07,  1.19steps/s, loss=0.045264155]     20%|██        | 20/100 [00:17<01:07,  1.19steps/s, loss=0.043061756]     21%|██        | 21/100 [00:18<01:05,  1.20steps/s, loss=0.043061756]     21%|██        | 21/100 [00:18<01:05,  1.20steps/s, loss=0.042848278]     22%|██▏       | 22/100 [00:19<01:10,  1.11steps/s, loss=0.042848278]     22%|██▏       | 22/100 [00:19<01:10,  1.11steps/s, loss=0.044271994]     23%|██▎       | 23/100 [00:20<01:07,  1.14steps/s, loss=0.044271994]     23%|██▎       | 23/100 [00:20<01:07,  1.14steps/s, loss=0.041491076]     24%|██▍       | 24/100 [00:21<01:06,  1.14steps/s, loss=0.041491076]     24%|██▍       | 24/100 [00:21<01:06,  1.14steps/s, loss=0.039383393]     25%|██▌       | 25/100 [00:22<01:06,  1.13steps/s, loss=0.039383393]     25%|██▌       | 25/100 [00:22<01:06,  1.13steps/s, loss=0.039678693]     26%|██▌       | 26/100 [00:22<01:06,  1.11steps/s, loss=0.039678693]     26%|██▌       | 26/100 [00:23<01:06,  1.11steps/s, loss=0.039221454]     27%|██▋       | 27/100 [00:23<01:06,  1.09steps/s, loss=0.039221454]     27%|██▋       | 27/100 [00:24<01:06,  1.09steps/s, loss=0.038447626]     28%|██▊       | 28/100 [00:24<01:06,  1.09steps/s, loss=0.038447626]     28%|██▊       | 28/100 [00:25<01:06,  1.09steps/s, loss=0.038569134]     29%|██▉       | 29/100 [00:25<01:02,  1.13steps/s, loss=0.038569134]     29%|██▉       | 29/100 [00:25<01:02,  1.13steps/s, loss=0.037667014]     30%|███       | 30/100 [00:26<00:59,  1.18steps/s, loss=0.037667014]     30%|███       | 30/100 [00:26<00:59,  1.18steps/s, loss=0.03789933]      31%|███       | 31/100 [00:27<01:02,  1.10steps/s, loss=0.03789933]     31%|███       | 31/100 [00:27<01:02,  1.10steps/s, loss=0.039813332]     32%|███▏      | 32/100 [00:28<01:00,  1.13steps/s, loss=0.039813332]     32%|███▏      | 32/100 [00:28<01:00,  1.13steps/s, loss=0.037319414]     33%|███▎      | 33/100 [00:29<00:58,  1.15steps/s, loss=0.037319414]     33%|███▎      | 33/100 [00:29<00:58,  1.15steps/s, loss=0.036911815]     34%|███▍      | 34/100 [00:29<00:55,  1.18steps/s, loss=0.036911815]     34%|███▍      | 34/100 [00:30<00:55,  1.18steps/s, loss=0.036391005]     35%|███▌      | 35/100 [00:30<00:54,  1.20steps/s, loss=0.036391005]     35%|███▌      | 35/100 [00:30<00:54,  1.20steps/s, loss=0.03494814]      36%|███▌      | 36/100 [00:31<00:53,  1.21steps/s, loss=0.03494814]     36%|███▌      | 36/100 [00:31<00:53,  1.21steps/s, loss=0.03520071]     37%|███▋      | 37/100 [00:32<00:52,  1.19steps/s, loss=0.03520071]     37%|███▋      | 37/100 [00:32<00:52,  1.19steps/s, loss=0.034577407]     38%|███▊      | 38/100 [00:33<00:51,  1.20steps/s, loss=0.034577407]     38%|███▊      | 38/100 [00:33<00:51,  1.20steps/s, loss=0.03381388]      39%|███▉      | 39/100 [00:34<00:52,  1.16steps/s, loss=0.03381388]     39%|███▉      | 39/100 [00:34<00:52,  1.16steps/s, loss=0.033282667]     40%|████      | 40/100 [00:35<00:52,  1.14steps/s, loss=0.033282667]     40%|████      | 40/100 [00:35<00:52,  1.14steps/s, loss=0.033057332]     41%|████      | 41/100 [00:36<00:56,  1.04steps/s, loss=0.033057332]     41%|████      | 41/100 [00:36<00:56,  1.04steps/s, loss=0.033095635]     42%|████▏     | 42/100 [00:37<00:54,  1.05steps/s, loss=0.033095635]     42%|████▏     | 42/100 [00:37<00:54,  1.05steps/s, loss=0.03409259]      43%|████▎     | 43/100 [00:37<00:50,  1.12steps/s, loss=0.03409259]     43%|████▎     | 43/100 [00:38<00:50,  1.12steps/s, loss=0.03302691]     44%|████▍     | 44/100 [00:38<00:47,  1.18steps/s, loss=0.03302691]     44%|████▍     | 44/100 [00:38<00:47,  1.18steps/s, loss=0.033529613]     45%|████▌     | 45/100 [00:39<00:46,  1.19steps/s, loss=0.033529613]     45%|████▌     | 45/100 [00:39<00:46,  1.19steps/s, loss=0.031866148]     46%|████▌     | 46/100 [00:40<00:44,  1.22steps/s, loss=0.031866148]     46%|████▌     | 46/100 [00:40<00:44,  1.22steps/s, loss=0.03150003]      47%|████▋     | 47/100 [00:40<00:42,  1.24steps/s, loss=0.03150003]     47%|████▋     | 47/100 [00:41<00:42,  1.24steps/s, loss=0.032285925]     48%|████▊     | 48/100 [00:41<00:41,  1.25steps/s, loss=0.032285925]     48%|████▊     | 48/100 [00:41<00:41,  1.25steps/s, loss=0.03266958]      49%|████▉     | 49/100 [00:42<00:40,  1.25steps/s, loss=0.03266958]     49%|████▉     | 49/100 [00:42<00:40,  1.25steps/s, loss=0.031885654]     50%|█████     | 50/100 [00:43<00:44,  1.11steps/s, loss=0.031885654]     50%|█████     | 50/100 [00:43<00:44,  1.11steps/s, loss=0.03184133]      51%|█████     | 51/100 [00:44<00:45,  1.08steps/s, loss=0.03184133]     51%|█████     | 51/100 [00:44<00:45,  1.08steps/s, loss=0.03217215]     52%|█████▏    | 52/100 [00:45<00:45,  1.06steps/s, loss=0.03217215]     52%|█████▏    | 52/100 [00:45<00:45,  1.06steps/s, loss=0.03346]        53%|█████▎    | 53/100 [00:46<00:45,  1.04steps/s, loss=0.03346]     53%|█████▎    | 53/100 [00:47<00:45,  1.04steps/s, loss=0.032274544]     54%|█████▍    | 54/100 [00:47<00:46,  1.01s/steps, loss=0.032274544]     54%|█████▍    | 54/100 [00:48<00:46,  1.01s/steps, loss=0.02926758]      55%|█████▌    | 55/100 [00:49<00:48,  1.08s/steps, loss=0.02926758]     55%|█████▌    | 55/100 [00:49<00:48,  1.08s/steps, loss=0.032024536]     56%|█████▌    | 56/100 [00:50<00:46,  1.05s/steps, loss=0.032024536]     56%|█████▌    | 56/100 [00:50<00:46,  1.05s/steps, loss=0.032741405]     57%|█████▋    | 57/100 [00:51<00:45,  1.06s/steps, loss=0.032741405]     57%|█████▋    | 57/100 [00:51<00:45,  1.06s/steps, loss=0.03016507]      58%|█████▊    | 58/100 [00:52<00:45,  1.08s/steps, loss=0.03016507]     58%|█████▊    | 58/100 [00:52<00:45,  1.08s/steps, loss=0.029202085]     59%|█████▉    | 59/100 [00:53<00:46,  1.14s/steps, loss=0.029202085]     59%|█████▉    | 59/100 [00:53<00:46,  1.14s/steps, loss=0.02962668]      60%|██████    | 60/100 [00:54<00:43,  1.09s/steps, loss=0.02962668]     60%|██████    | 60/100 [00:54<00:43,  1.09s/steps, loss=0.031430278]     61%|██████    | 61/100 [00:55<00:42,  1.09s/steps, loss=0.031430278]     61%|██████    | 61/100 [00:55<00:42,  1.09s/steps, loss=0.03109225]      62%|██████▏   | 62/100 [00:56<00:40,  1.07s/steps, loss=0.03109225]     62%|██████▏   | 62/100 [00:56<00:40,  1.07s/steps, loss=0.029951882]     63%|██████▎   | 63/100 [00:57<00:40,  1.08s/steps, loss=0.029951882]     63%|██████▎   | 63/100 [00:57<00:40,  1.08s/steps, loss=0.029345399]     64%|██████▍   | 64/100 [00:58<00:39,  1.09s/steps, loss=0.029345399]     64%|██████▍   | 64/100 [00:59<00:39,  1.09s/steps, loss=0.028397541]     65%|██████▌   | 65/100 [01:00<00:39,  1.13s/steps, loss=0.028397541]     65%|██████▌   | 65/100 [01:00<00:39,  1.13s/steps, loss=0.028493088]     66%|██████▌   | 66/100 [01:01<00:40,  1.18s/steps, loss=0.028493088]     66%|██████▌   | 66/100 [01:01<00:40,  1.18s/steps, loss=0.028109204]     67%|██████▋   | 67/100 [01:02<00:38,  1.16s/steps, loss=0.028109204]     67%|██████▋   | 67/100 [01:02<00:38,  1.16s/steps, loss=0.027203772]     68%|██████▊   | 68/100 [01:03<00:33,  1.05s/steps, loss=0.027203772]     68%|██████▊   | 68/100 [01:03<00:33,  1.05s/steps, loss=0.02842273]      69%|██████▉   | 69/100 [01:04<00:33,  1.07s/steps, loss=0.02842273]     69%|██████▉   | 69/100 [01:04<00:33,  1.07s/steps, loss=0.03021006]     70%|███████   | 70/100 [01:05<00:30,  1.03s/steps, loss=0.03021006]     70%|███████   | 70/100 [01:05<00:30,  1.03s/steps, loss=0.027492268]     71%|███████   | 71/100 [01:06<00:28,  1.01steps/s, loss=0.027492268]     71%|███████   | 71/100 [01:06<00:28,  1.01steps/s, loss=0.027220147]     72%|███████▏  | 72/100 [01:07<00:26,  1.04steps/s, loss=0.027220147]     72%|███████▏  | 72/100 [01:07<00:26,  1.04steps/s, loss=0.028448489]     73%|███████▎  | 73/100 [01:07<00:25,  1.07steps/s, loss=0.028448489]     73%|███████▎  | 73/100 [01:08<00:25,  1.07steps/s, loss=0.028300524]     74%|███████▍  | 74/100 [01:08<00:24,  1.05steps/s, loss=0.028300524]     74%|███████▍  | 74/100 [01:09<00:24,  1.05steps/s, loss=0.027671438]     75%|███████▌  | 75/100 [01:09<00:23,  1.06steps/s, loss=0.027671438]     75%|███████▌  | 75/100 [01:10<00:23,  1.06steps/s, loss=0.027673326]     76%|███████▌  | 76/100 [01:10<00:21,  1.10steps/s, loss=0.027673326]     76%|███████▌  | 76/100 [01:11<00:21,  1.10steps/s, loss=0.026839104]     77%|███████▋  | 77/100 [01:11<00:21,  1.09steps/s, loss=0.026839104]     77%|███████▋  | 77/100 [01:12<00:21,  1.09steps/s, loss=0.026480783]     78%|███████▊  | 78/100 [01:12<00:22,  1.02s/steps, loss=0.026480783]     78%|███████▊  | 78/100 [01:13<00:22,  1.02s/steps, loss=0.026687844]     79%|███████▉  | 79/100 [01:13<00:19,  1.06steps/s, loss=0.026687844]     79%|███████▉  | 79/100 [01:13<00:19,  1.06steps/s, loss=0.027393278]     80%|████████  | 80/100 [01:14<00:18,  1.09steps/s, loss=0.027393278]     80%|████████  | 80/100 [01:14<00:18,  1.09steps/s, loss=0.027203083]     81%|████████  | 81/100 [01:15<00:16,  1.13steps/s, loss=0.027203083]     81%|████████  | 81/100 [01:15<00:16,  1.13steps/s, loss=0.026574159]     82%|████████▏ | 82/100 [01:16<00:15,  1.15steps/s, loss=0.026574159]     82%|████████▏ | 82/100 [01:16<00:15,  1.15steps/s, loss=0.025880413]     83%|████████▎ | 83/100 [01:17<00:14,  1.15steps/s, loss=0.025880413]     83%|████████▎ | 83/100 [01:17<00:14,  1.15steps/s, loss=0.025318203]     84%|████████▍ | 84/100 [01:17<00:13,  1.16steps/s, loss=0.025318203]     84%|████████▍ | 84/100 [01:18<00:13,  1.16steps/s, loss=0.025523087]     85%|████████▌ | 85/100 [01:18<00:13,  1.07steps/s, loss=0.025523087]     85%|████████▌ | 85/100 [01:19<00:13,  1.07steps/s, loss=0.025832474]     86%|████████▌ | 86/100 [01:19<00:12,  1.08steps/s, loss=0.025832474]     86%|████████▌ | 86/100 [01:20<00:12,  1.08steps/s, loss=0.026079997]     87%|████████▋ | 87/100 [01:20<00:11,  1.09steps/s, loss=0.026079997]     87%|████████▋ | 87/100 [01:20<00:11,  1.09steps/s, loss=0.026039068]     88%|████████▊ | 88/100 [01:21<00:11,  1.04steps/s, loss=0.026039068]     88%|████████▊ | 88/100 [01:22<00:11,  1.04steps/s, loss=0.025411729]     89%|████████▉ | 89/100 [01:22<00:10,  1.08steps/s, loss=0.025411729]     89%|████████▉ | 89/100 [01:22<00:10,  1.08steps/s, loss=0.02490239]      90%|█████████ | 90/100 [01:23<00:09,  1.11steps/s, loss=0.02490239]     90%|█████████ | 90/100 [01:23<00:09,  1.11steps/s, loss=0.02467421]     91%|█████████ | 91/100 [01:24<00:07,  1.17steps/s, loss=0.02467421]     91%|█████████ | 91/100 [01:24<00:07,  1.17steps/s, loss=0.024658125]     92%|█████████▏| 92/100 [01:25<00:06,  1.21steps/s, loss=0.024658125]     92%|█████████▏| 92/100 [01:25<00:06,  1.21steps/s, loss=0.02464765]      93%|█████████▎| 93/100 [01:25<00:05,  1.21steps/s, loss=0.02464765]     93%|█████████▎| 93/100 [01:26<00:05,  1.21steps/s, loss=0.024624482]     94%|█████████▍| 94/100 [01:26<00:04,  1.23steps/s, loss=0.024624482]     94%|█████████▍| 94/100 [01:26<00:04,  1.23steps/s, loss=0.024571199]     95%|█████████▌| 95/100 [01:27<00:04,  1.21steps/s, loss=0.024571199]     95%|█████████▌| 95/100 [01:27<00:04,  1.21steps/s, loss=0.02463552]      96%|█████████▌| 96/100 [01:28<00:03,  1.20steps/s, loss=0.02463552]     96%|█████████▌| 96/100 [01:28<00:03,  1.20steps/s, loss=0.024536982]     97%|█████████▋| 97/100 [01:29<00:02,  1.09steps/s, loss=0.024536982]     97%|█████████▋| 97/100 [01:29<00:02,  1.09steps/s, loss=0.02435083]      98%|█████████▊| 98/100 [01:30<00:01,  1.11steps/s, loss=0.02435083]     98%|█████████▊| 98/100 [01:30<00:01,  1.11steps/s, loss=0.02438885]     99%|█████████▉| 99/100 [01:31<00:00,  1.12steps/s, loss=0.02438885]     99%|█████████▉| 99/100 [01:31<00:00,  1.12steps/s, loss=0.02427794]    100%|██████████| 100/100 [01:32<00:00,  1.14steps/s, loss=0.02427794]    100%|██████████| 100/100 [01:32<00:00,  1.09steps/s, loss=0.02427794]




.. GENERATED FROM PYTHON SOURCE LINES 244-248

.. image-sg:: /generated/autoexamples/GPU/images/mrinufft_learn_traj_mc.gif
   :alt: example learn_samples
   :srcset: /generated/autoexamples/GPU/images/mrinufft_learn_traj_mc.gif
   :class: sphx-glr-single-img

.. GENERATED FROM PYTHON SOURCE LINES 250-252

Trained trajectory
------------------

.. GENERATED FROM PYTHON SOURCE LINES 252-259

.. code-block:: Python

    model.eval()
    recon = model(mcmri_2D)
    fig, axs = plt.subplots(2, 2, figsize=(10, 10))
    plot_state(axs, mri_2D, model.trajectory.detach().cpu().numpy(), recon, losses)
    plt.show()





.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_003.png
   :alt: MR Image, Trajectory, Reconstruction, Loss
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 260-275

References
==========

.. [Proj] N. Chauffert, P. Weiss, J. Kahn and P. Ciuciu, "A Projection Algorithm for
          Gradient Waveforms Design in Magnetic Resonance Imaging," in
          IEEE Transactions on Medical Imaging, vol. 35, no. 9, pp. 2026-2039, Sept. 2016,
          doi: 10.1109/TMI.2016.2544251.
.. [Sparks] G. R. Chaithya, P. Weiss, G. Daval-Frérot, A. Massire, A. Vignaud and P. Ciuciu,
          "Optimizing Full 3D SPARKLING Trajectories for High-Resolution Magnetic
          Resonance Imaging," in IEEE Transactions on Medical Imaging, vol. 41, no. 8,
          pp. 2105-2117, Aug. 2022, doi: 10.1109/TMI.2022.3157269.
.. [Projector] Chaithya GR, and Philippe Ciuciu. 2023. "Jointly Learning Non-Cartesian
          k-Space Trajectories and Reconstruction Networks for 2D and 3D MR Imaging
          through Projection" Bioengineering 10, no. 2: 158.
          https://doi.org/10.3390/bioengineering10020158


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 39.963 seconds)


.. _sphx_glr_download_generated_autoexamples_GPU_example_learn_samples_multicoil.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/mind-inria/mri-nufft/gh-pages?urlpath=lab/tree/examples/generated/autoexamples/GPU/example_learn_samples_multicoil.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: example_learn_samples_multicoil.ipynb <example_learn_samples_multicoil.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: example_learn_samples_multicoil.py <example_learn_samples_multicoil.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: example_learn_samples_multicoil.zip <example_learn_samples_multicoil.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
