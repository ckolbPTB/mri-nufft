
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "generated/autoexamples/GPU/example_learn_samples_multicoil.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_generated_autoexamples_GPU_example_learn_samples_multicoil.py>`
        to download the full example code. or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_generated_autoexamples_GPU_example_learn_samples_multicoil.py:


=========================================
Learn Sampling pattern for multi-coil MRI
=========================================

A small pytorch example to showcase learning k-space sampling patterns.
This example showcases the auto-diff capabilities of the NUFFT operator 
wrt to k-space trajectory in mri-nufft.

Briefly, in this example we try to learn the k-space samples :math:`\mathbf{K}` for the following cost function:

.. math::

    \mathbf{\hat{K}} =  arg \min_{\mathbf{K}} ||  \sum_{\ell=1}^LS_\ell^* \mathcal{F}_\mathbf{K}^* D_\mathbf{K} \mathcal{F}_\mathbf{K} x_\ell - \mathbf{x}_{sos} ||_2^2 
    
where :math:`S_\ell` is the sensitivity map for the :math:`\ell`-th coil, :math:`\mathcal{F}_\mathbf{K}` is the forward NUFFT operator and :math:`D_\mathbf{K}` is the density compensators for trajectory :math:`\mathbf{K}`,  :math:`\mathbf{x}_\ell` is the image for the :math:`\ell`-th coil, and :math:`\mathbf{x}_{sos} = \sqrt{\sum_{\ell=1}^L x_\ell^2}` is the sum-of-squares image as target image to be reconstructed.

In this example, the forward NUFFT operator :math:`\mathcal{F}_\mathbf{K}` is implemented with `model.operator` while the SENSE operator :math:`model.sense_op` models the term :math:`\mathbf{A} = \sum_{\ell=1}^LS_\ell^* \mathcal{F}_\mathbf{K}^* D_\mathbf{K}`.
For our data, we use a 2D slice of a 3D MRI image from the BrainWeb dataset, and the sensitivity maps are simulated using the `birdcage_maps` function from `sigpy.mri`.

.. note::
    To showcase the features of ``mri-nufft``, we use ``
    "cufinufft"`` backend for ``model.operator`` without density compensation and ``"gpunufft"`` backend for ``model.sense_op`` with density compensation. 
    
.. warning::
    This example only showcases the autodiff capabilities, the learned sampling pattern is not scanner compliant as the scanner gradients required to implement it violate the hardware constraints. In practice, a projection :math:`\Pi_\mathcal{Q}(\mathbf{K})` into the scanner constraints set :math:`\mathcal{Q}` is recommended (see [Proj]_). This is implemented in the proprietary SPARKLING package [Sparks]_. Users are encouraged to contact the authors if they want to use it.

.. GENERATED FROM PYTHON SOURCE LINES 30-34

.. colab-link::
   :needs_gpu: 1

   !pip install mri-nufft[gpunufft] cufinufft sigpy scikit-image

.. GENERATED FROM PYTHON SOURCE LINES 36-38

Imports
-------

.. GENERATED FROM PYTHON SOURCE LINES 38-53

.. code-block:: Python

    import time
    import joblib

    import brainweb_dl as bwdl
    import matplotlib.pyplot as plt
    import numpy as np
    import torch
    from tqdm import tqdm
    from PIL import Image, ImageSequence

    from mrinufft import get_operator
    from mrinufft.extras import get_smaps
    from mrinufft.trajectories import initialize_2D_radial
    from sigpy.mri import birdcage_maps








.. GENERATED FROM PYTHON SOURCE LINES 54-59

Setup a simple class to learn trajectory
----------------------------------------
.. note::
    While we are only learning the NUFFT operator, we still need the gradient `wrt_data=True` to have all the gradients computed correctly.
    See [Projector]_ for more details.

.. GENERATED FROM PYTHON SOURCE LINES 59-115

.. code-block:: Python



    class Model(torch.nn.Module):
        def __init__(self, inital_trajectory, n_coils, img_size=(256, 256)):
            super(Model, self).__init__()
            self.trajectory = torch.nn.Parameter(
                data=torch.Tensor(inital_trajectory),
                requires_grad=True,
            )
            sample_points = inital_trajectory.reshape(-1, inital_trajectory.shape[-1])
            # A simple acquisition model simulated with a forward NUFFT operator. We dont need density compensation here.
            # The trajectory is scaled by 2*pi for cufinufft backend.
            self.operator = get_operator("cufinufft", wrt_data=True, wrt_traj=True)(
                sample_points * 2 * np.pi,
                shape=img_size,
                n_coils=n_coils,
                squeeze_dims=False,
            )
            # A simple density compensated adjoint SENSE operator with sensitivity maps `smaps`.
            self.sense_op = get_operator("gpunufft", wrt_data=True, wrt_traj=True)(
                sample_points,
                shape=img_size,
                density=True,
                n_coils=n_coils,
                smaps=np.ones(
                    (n_coils, *img_size)
                ),  # Dummy smaps, this is updated in forward pass
                squeeze_dims=False,
            )
            self.img_size = img_size

        def forward(self, x):
            """Forward pass of the model."""
            # Update the trajectory in the NUFFT operator.
            # The trajectory is scaled by 2*pi for cufinufft backend.
            # Note that the re-computation of density compensation happens internally.
            self.operator.samples = self.trajectory.clone() * 2 * np.pi
            self.sense_op.samples = self.trajectory.clone()

            # Simulate the acquisition process
            kspace = self.operator.op(x)

            # Recompute the sensitivity maps for the updated trajectory.
            self.sense_op.smaps, _ = get_smaps("low_frequency")(
                self.trajectory.detach().numpy(),
                self.img_size,
                kspace.detach(),
                backend="gpunufft",
                density=self.sense_op.density,
                blurr_factor=20,
            )
            # Reconstruction using the sense operator
            adjoint = self.sense_op.adj_op(kspace).abs()
            return adjoint / torch.mean(adjoint)









.. GENERATED FROM PYTHON SOURCE LINES 116-118

Util function to plot the state of the model
--------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 118-139

.. code-block:: Python

    def plot_state(axs, mri_2D, traj, recon, loss=None, save_name=None):
        axs = axs.flatten()
        axs[0].imshow(np.abs(mri_2D), cmap="gray")
        axs[0].axis("off")
        axs[0].set_title("MR Image")
        axs[1].scatter(*traj.T, s=1)
        axs[1].set_title("Trajectory")
        axs[2].imshow(np.abs(recon[0][0].detach().cpu().numpy()), cmap="gray")
        axs[2].axis("off")
        axs[2].set_title("Reconstruction")
        if loss is not None:
            axs[3].plot(loss)
            axs[3].set_title("Loss")
            axs[3].grid("on")
        if save_name is not None:
            plt.savefig(save_name, bbox_inches="tight")
            plt.close()
        else:
            plt.show()









.. GENERATED FROM PYTHON SOURCE LINES 140-142

Setup model and optimizer
-------------------------

.. GENERATED FROM PYTHON SOURCE LINES 142-152

.. code-block:: Python

    n_coils = 6
    init_traj = initialize_2D_radial(32, 256).astype(np.float32).reshape(-1, 2)
    model = Model(init_traj, n_coils=n_coils, img_size=(256, 256))
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    schedulder = torch.optim.lr_scheduler.LinearLR(
        optimizer,
        start_factor=1,
        end_factor=0.1,
        total_iters=100,
    )




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /volatile/github-ci-mind-inria/action-runner/_work/_tool/Python/3.10.14/x64/lib/python3.10/site-packages/mrinufft/operators/interfaces/gpunufft.py:146: UserWarning: no pinning provided, pinning existing smaps now.
      warnings.warn("no pinning provided, pinning existing smaps now.")




.. GENERATED FROM PYTHON SOURCE LINES 153-155

Setup data
----------

.. GENERATED FROM PYTHON SOURCE LINES 155-164

.. code-block:: Python

    mri_2D = torch.from_numpy(np.flipud(bwdl.get_mri(4, "T1")[80, ...]).astype(np.float32))
    mri_2D = mri_2D / torch.mean(mri_2D)
    smaps_simulated = torch.from_numpy(birdcage_maps((n_coils, *mri_2D.shape)))
    mcmri_2D = mri_2D[None].to(torch.complex64) * smaps_simulated
    model.eval()
    recon = model(mcmri_2D)
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    plot_state(axs, mri_2D, model.trajectory.detach().cpu().numpy(), recon)




.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_001.png
   :alt: MR Image, Trajectory, Reconstruction
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 165-167

Start training loop
-------------------

.. GENERATED FROM PYTHON SOURCE LINES 167-215

.. code-block:: Python

    losses = []
    image_files = []
    model.train()

    with tqdm(range(100), unit="steps") as tqdms:
        for i in tqdms:
            out = model(mcmri_2D)
            loss = torch.nn.functional.mse_loss(out, mri_2D[None, None])
            numpy_loss = loss.detach().cpu().numpy()
            tqdms.set_postfix({"loss": numpy_loss})
            losses.append(numpy_loss)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            schedulder.step()
            with torch.no_grad():
                # Clamp the value of trajectory between [-0.5, 0.5]
                for param in model.parameters():
                    param.clamp_(-0.5, 0.5)
            # Generate images for gif
            hashed = joblib.hash((i, "learn_traj", time.time()))
            filename = "/tmp/" + f"{hashed}.png"
            plt.clf()
            fig, axs = plt.subplots(2, 2, figsize=(10, 10))
            plot_state(
                axs,
                mri_2D,
                model.trajectory.detach().cpu().numpy(),
                out,
                losses,
                save_name=filename,
            )
            image_files.append(filename)


    # Make a GIF of all images.
    imgs = [Image.open(img) for img in image_files]
    imgs[0].save(
        "mrinufft_learn_traj_mc.gif",
        save_all=True,
        append_images=imgs[1:],
        optimize=False,
        duration=2,
        loop=0,
    )

    # sphinx_gallery_thumbnail_path = 'generated/autoexamples/GPU/images/mrinufft_learn_traj_mc.gif'




.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_002.png
   :alt: example learn samples multicoil
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/100 [00:00<?, ?steps/s]      0%|          | 0/100 [00:00<?, ?steps/s, loss=0.15466066]/volatile/github-ci-mind-inria/action-runner/_work/_tool/Python/3.10.14/x64/lib/python3.10/site-packages/mrinufft/operators/autodiff.py:98: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:305.)
      grad_traj = torch.transpose(torch.sum(grad_traj, dim=1), 0, 1).to(
      1%|          | 1/100 [00:00<01:18,  1.26steps/s, loss=0.15466066]      1%|          | 1/100 [00:00<01:18,  1.26steps/s, loss=0.2720747]       2%|▏         | 2/100 [00:01<01:15,  1.31steps/s, loss=0.2720747]      2%|▏         | 2/100 [00:01<01:15,  1.31steps/s, loss=0.21598715]      3%|▎         | 3/100 [00:02<01:12,  1.33steps/s, loss=0.21598715]      3%|▎         | 3/100 [00:02<01:12,  1.33steps/s, loss=0.12371829]      4%|▍         | 4/100 [00:03<01:12,  1.33steps/s, loss=0.12371829]      4%|▍         | 4/100 [00:03<01:12,  1.33steps/s, loss=0.10388478]      5%|▌         | 5/100 [00:03<01:12,  1.32steps/s, loss=0.10388478]      5%|▌         | 5/100 [00:03<01:12,  1.32steps/s, loss=0.09459698]      6%|▌         | 6/100 [00:04<01:17,  1.22steps/s, loss=0.09459698]      6%|▌         | 6/100 [00:04<01:17,  1.22steps/s, loss=0.07855505]      7%|▋         | 7/100 [00:05<01:14,  1.25steps/s, loss=0.07855505]      7%|▋         | 7/100 [00:05<01:14,  1.25steps/s, loss=0.08227359]      8%|▊         | 8/100 [00:06<01:13,  1.26steps/s, loss=0.08227359]      8%|▊         | 8/100 [00:06<01:13,  1.26steps/s, loss=0.076160364]      9%|▉         | 9/100 [00:07<01:11,  1.27steps/s, loss=0.076160364]      9%|▉         | 9/100 [00:07<01:11,  1.27steps/s, loss=0.06720503]      10%|█         | 10/100 [00:07<01:09,  1.30steps/s, loss=0.06720503]     10%|█         | 10/100 [00:07<01:09,  1.30steps/s, loss=0.06416902]     11%|█         | 11/100 [00:08<01:08,  1.31steps/s, loss=0.06416902]     11%|█         | 11/100 [00:08<01:08,  1.31steps/s, loss=0.059034407]     12%|█▏        | 12/100 [00:09<01:06,  1.32steps/s, loss=0.059034407]     12%|█▏        | 12/100 [00:09<01:06,  1.32steps/s, loss=0.05895597]      13%|█▎        | 13/100 [00:10<01:06,  1.31steps/s, loss=0.05895597]     13%|█▎        | 13/100 [00:10<01:06,  1.31steps/s, loss=0.05661534]     14%|█▍        | 14/100 [00:11<01:11,  1.20steps/s, loss=0.05661534]     14%|█▍        | 14/100 [00:11<01:11,  1.20steps/s, loss=0.05274141]     15%|█▌        | 15/100 [00:11<01:09,  1.23steps/s, loss=0.05274141]     15%|█▌        | 15/100 [00:11<01:09,  1.23steps/s, loss=0.051433563]     16%|█▌        | 16/100 [00:12<01:06,  1.26steps/s, loss=0.051433563]     16%|█▌        | 16/100 [00:12<01:06,  1.26steps/s, loss=0.048921496]     17%|█▋        | 17/100 [00:13<01:05,  1.27steps/s, loss=0.048921496]     17%|█▋        | 17/100 [00:13<01:05,  1.27steps/s, loss=0.048134886]     18%|█▊        | 18/100 [00:14<01:03,  1.29steps/s, loss=0.048134886]     18%|█▊        | 18/100 [00:14<01:03,  1.29steps/s, loss=0.046520215]     19%|█▉        | 19/100 [00:14<01:02,  1.30steps/s, loss=0.046520215]     19%|█▉        | 19/100 [00:15<01:02,  1.30steps/s, loss=0.04502324]      20%|██        | 20/100 [00:15<01:00,  1.32steps/s, loss=0.04502324]     20%|██        | 20/100 [00:15<01:00,  1.32steps/s, loss=0.042830598]     21%|██        | 21/100 [00:16<00:59,  1.32steps/s, loss=0.042830598]     21%|██        | 21/100 [00:16<00:59,  1.32steps/s, loss=0.043391906]     22%|██▏       | 22/100 [00:17<01:00,  1.30steps/s, loss=0.043391906]     22%|██▏       | 22/100 [00:17<01:00,  1.30steps/s, loss=0.04193438]      23%|██▎       | 23/100 [00:18<01:03,  1.22steps/s, loss=0.04193438]     23%|██▎       | 23/100 [00:18<01:03,  1.22steps/s, loss=0.039350785]     24%|██▍       | 24/100 [00:18<01:00,  1.26steps/s, loss=0.039350785]     24%|██▍       | 24/100 [00:18<01:00,  1.26steps/s, loss=0.039615028]     25%|██▌       | 25/100 [00:19<00:58,  1.29steps/s, loss=0.039615028]     25%|██▌       | 25/100 [00:19<00:58,  1.29steps/s, loss=0.040106043]     26%|██▌       | 26/100 [00:20<00:57,  1.30steps/s, loss=0.040106043]     26%|██▌       | 26/100 [00:20<00:57,  1.30steps/s, loss=0.040004678]     27%|██▋       | 27/100 [00:21<00:55,  1.31steps/s, loss=0.040004678]     27%|██▋       | 27/100 [00:21<00:55,  1.31steps/s, loss=0.038710434]     28%|██▊       | 28/100 [00:21<00:54,  1.33steps/s, loss=0.038710434]     28%|██▊       | 28/100 [00:21<00:54,  1.33steps/s, loss=0.040977575]     29%|██▉       | 29/100 [00:22<00:53,  1.34steps/s, loss=0.040977575]     29%|██▉       | 29/100 [00:22<00:53,  1.34steps/s, loss=0.037179466]     30%|███       | 30/100 [00:23<00:52,  1.33steps/s, loss=0.037179466]     30%|███       | 30/100 [00:23<00:52,  1.33steps/s, loss=0.03715846]      31%|███       | 31/100 [00:24<00:51,  1.33steps/s, loss=0.03715846]     31%|███       | 31/100 [00:24<00:51,  1.33steps/s, loss=0.037849154]     32%|███▏      | 32/100 [00:24<00:55,  1.22steps/s, loss=0.037849154]     32%|███▏      | 32/100 [00:25<00:55,  1.22steps/s, loss=0.035385184]     33%|███▎      | 33/100 [00:25<00:53,  1.25steps/s, loss=0.035385184]     33%|███▎      | 33/100 [00:25<00:53,  1.25steps/s, loss=0.0344934]       34%|███▍      | 34/100 [00:26<00:51,  1.28steps/s, loss=0.0344934]     34%|███▍      | 34/100 [00:26<00:51,  1.28steps/s, loss=0.03520965]     35%|███▌      | 35/100 [00:27<00:50,  1.29steps/s, loss=0.03520965]     35%|███▌      | 35/100 [00:27<00:50,  1.29steps/s, loss=0.03450261]     36%|███▌      | 36/100 [00:27<00:49,  1.30steps/s, loss=0.03450261]     36%|███▌      | 36/100 [00:28<00:49,  1.30steps/s, loss=0.034411937]     37%|███▋      | 37/100 [00:28<00:51,  1.23steps/s, loss=0.034411937]     37%|███▋      | 37/100 [00:29<00:51,  1.23steps/s, loss=0.035108477]     38%|███▊      | 38/100 [00:29<00:54,  1.13steps/s, loss=0.035108477]     38%|███▊      | 38/100 [00:30<00:54,  1.13steps/s, loss=0.034433503]     39%|███▉      | 39/100 [00:30<00:53,  1.14steps/s, loss=0.034433503]     39%|███▉      | 39/100 [00:31<00:53,  1.14steps/s, loss=0.034074835]     40%|████      | 40/100 [00:31<00:50,  1.20steps/s, loss=0.034074835]     40%|████      | 40/100 [00:31<00:50,  1.20steps/s, loss=0.03398238]      41%|████      | 41/100 [00:32<00:51,  1.15steps/s, loss=0.03398238]     41%|████      | 41/100 [00:32<00:51,  1.15steps/s, loss=0.033948712]     42%|████▏     | 42/100 [00:33<00:48,  1.20steps/s, loss=0.033948712]     42%|████▏     | 42/100 [00:33<00:48,  1.20steps/s, loss=0.03328996]      43%|████▎     | 43/100 [00:33<00:45,  1.24steps/s, loss=0.03328996]     43%|████▎     | 43/100 [00:34<00:45,  1.24steps/s, loss=0.032892916]     44%|████▍     | 44/100 [00:34<00:43,  1.28steps/s, loss=0.032892916]     44%|████▍     | 44/100 [00:34<00:43,  1.28steps/s, loss=0.033818603]     45%|████▌     | 45/100 [00:35<00:42,  1.31steps/s, loss=0.033818603]     45%|████▌     | 45/100 [00:35<00:42,  1.31steps/s, loss=0.03336606]      46%|████▌     | 46/100 [00:36<00:40,  1.32steps/s, loss=0.03336606]     46%|████▌     | 46/100 [00:36<00:40,  1.32steps/s, loss=0.032565884]     47%|████▋     | 47/100 [00:36<00:39,  1.33steps/s, loss=0.032565884]     47%|████▋     | 47/100 [00:37<00:39,  1.33steps/s, loss=0.032699347]     48%|████▊     | 48/100 [00:37<00:39,  1.32steps/s, loss=0.032699347]     48%|████▊     | 48/100 [00:37<00:39,  1.32steps/s, loss=0.033183545]     49%|████▉     | 49/100 [00:38<00:37,  1.34steps/s, loss=0.033183545]     49%|████▉     | 49/100 [00:38<00:37,  1.34steps/s, loss=0.031688306]     50%|█████     | 50/100 [00:39<00:40,  1.23steps/s, loss=0.031688306]     50%|█████     | 50/100 [00:39<00:40,  1.23steps/s, loss=0.030743334]     51%|█████     | 51/100 [00:40<00:39,  1.26steps/s, loss=0.030743334]     51%|█████     | 51/100 [00:40<00:39,  1.26steps/s, loss=0.033363387]     52%|█████▏    | 52/100 [00:40<00:37,  1.27steps/s, loss=0.033363387]     52%|█████▏    | 52/100 [00:41<00:37,  1.27steps/s, loss=0.031852838]     53%|█████▎    | 53/100 [00:41<00:36,  1.29steps/s, loss=0.031852838]     53%|█████▎    | 53/100 [00:41<00:36,  1.29steps/s, loss=0.03092774]      54%|█████▍    | 54/100 [00:42<00:35,  1.30steps/s, loss=0.03092774]     54%|█████▍    | 54/100 [00:42<00:35,  1.30steps/s, loss=0.03084379]     55%|█████▌    | 55/100 [00:43<00:34,  1.30steps/s, loss=0.03084379]     55%|█████▌    | 55/100 [00:43<00:34,  1.30steps/s, loss=0.031925708]     56%|█████▌    | 56/100 [00:43<00:33,  1.31steps/s, loss=0.031925708]     56%|█████▌    | 56/100 [00:44<00:33,  1.31steps/s, loss=0.032215983]     57%|█████▋    | 57/100 [00:44<00:32,  1.31steps/s, loss=0.032215983]     57%|█████▋    | 57/100 [00:44<00:32,  1.31steps/s, loss=0.030570384]     58%|█████▊    | 58/100 [00:45<00:32,  1.31steps/s, loss=0.030570384]     58%|█████▊    | 58/100 [00:45<00:32,  1.31steps/s, loss=0.030832615]     59%|█████▉    | 59/100 [00:46<00:34,  1.20steps/s, loss=0.030832615]     59%|█████▉    | 59/100 [00:46<00:34,  1.20steps/s, loss=0.03011465]      60%|██████    | 60/100 [00:47<00:32,  1.23steps/s, loss=0.03011465]     60%|██████    | 60/100 [00:47<00:32,  1.23steps/s, loss=0.028878767]     61%|██████    | 61/100 [00:47<00:31,  1.25steps/s, loss=0.028878767]     61%|██████    | 61/100 [00:48<00:31,  1.25steps/s, loss=0.029400064]     62%|██████▏   | 62/100 [00:48<00:30,  1.26steps/s, loss=0.029400064]     62%|██████▏   | 62/100 [00:49<00:30,  1.26steps/s, loss=0.029196694]     63%|██████▎   | 63/100 [00:49<00:29,  1.27steps/s, loss=0.029196694]     63%|██████▎   | 63/100 [00:49<00:29,  1.27steps/s, loss=0.028232118]     64%|██████▍   | 64/100 [00:50<00:28,  1.27steps/s, loss=0.028232118]     64%|██████▍   | 64/100 [00:50<00:28,  1.27steps/s, loss=0.02810708]      65%|██████▌   | 65/100 [00:51<00:27,  1.27steps/s, loss=0.02810708]     65%|██████▌   | 65/100 [00:51<00:27,  1.27steps/s, loss=0.028227577]     66%|██████▌   | 66/100 [00:51<00:26,  1.27steps/s, loss=0.028227577]     66%|██████▌   | 66/100 [00:52<00:26,  1.27steps/s, loss=0.027951868]     67%|██████▋   | 67/100 [00:52<00:26,  1.26steps/s, loss=0.027951868]     67%|██████▋   | 67/100 [00:52<00:26,  1.26steps/s, loss=0.02845788]      68%|██████▊   | 68/100 [00:53<00:27,  1.16steps/s, loss=0.02845788]     68%|██████▊   | 68/100 [00:53<00:27,  1.16steps/s, loss=0.02831781]     69%|██████▉   | 69/100 [00:54<00:26,  1.19steps/s, loss=0.02831781]     69%|██████▉   | 69/100 [00:54<00:26,  1.19steps/s, loss=0.027093826]     70%|███████   | 70/100 [00:55<00:24,  1.21steps/s, loss=0.027093826]     70%|███████   | 70/100 [00:55<00:24,  1.21steps/s, loss=0.026956439]     71%|███████   | 71/100 [00:56<00:24,  1.21steps/s, loss=0.026956439]     71%|███████   | 71/100 [00:56<00:24,  1.21steps/s, loss=0.026955996]     72%|███████▏  | 72/100 [00:56<00:22,  1.23steps/s, loss=0.026955996]     72%|███████▏  | 72/100 [00:57<00:22,  1.23steps/s, loss=0.026480982]     73%|███████▎  | 73/100 [00:57<00:21,  1.24steps/s, loss=0.026480982]     73%|███████▎  | 73/100 [00:57<00:21,  1.24steps/s, loss=0.026093125]     74%|███████▍  | 74/100 [00:58<00:20,  1.25steps/s, loss=0.026093125]     74%|███████▍  | 74/100 [00:58<00:20,  1.25steps/s, loss=0.02605873]      75%|███████▌  | 75/100 [00:59<00:19,  1.25steps/s, loss=0.02605873]     75%|███████▌  | 75/100 [00:59<00:19,  1.25steps/s, loss=0.0260353]      76%|███████▌  | 76/100 [01:00<00:19,  1.25steps/s, loss=0.0260353]     76%|███████▌  | 76/100 [01:00<00:19,  1.25steps/s, loss=0.026093643]     77%|███████▋  | 77/100 [01:01<00:19,  1.16steps/s, loss=0.026093643]     77%|███████▋  | 77/100 [01:01<00:19,  1.16steps/s, loss=0.026087724]     78%|███████▊  | 78/100 [01:01<00:18,  1.19steps/s, loss=0.026087724]     78%|███████▊  | 78/100 [01:02<00:18,  1.19steps/s, loss=0.025933746]     79%|███████▉  | 79/100 [01:02<00:17,  1.21steps/s, loss=0.025933746]     79%|███████▉  | 79/100 [01:02<00:17,  1.21steps/s, loss=0.02563063]      80%|████████  | 80/100 [01:03<00:16,  1.23steps/s, loss=0.02563063]     80%|████████  | 80/100 [01:03<00:16,  1.23steps/s, loss=0.025615837]     81%|████████  | 81/100 [01:04<00:15,  1.23steps/s, loss=0.025615837]     81%|████████  | 81/100 [01:04<00:15,  1.23steps/s, loss=0.02554912]      82%|████████▏ | 82/100 [01:05<00:14,  1.23steps/s, loss=0.02554912]     82%|████████▏ | 82/100 [01:05<00:14,  1.23steps/s, loss=0.025463887]     83%|████████▎ | 83/100 [01:05<00:13,  1.23steps/s, loss=0.025463887]     83%|████████▎ | 83/100 [01:06<00:13,  1.23steps/s, loss=0.025263812]     84%|████████▍ | 84/100 [01:06<00:12,  1.24steps/s, loss=0.025263812]     84%|████████▍ | 84/100 [01:06<00:12,  1.24steps/s, loss=0.024975961]     85%|████████▌ | 85/100 [01:07<00:12,  1.23steps/s, loss=0.024975961]     85%|████████▌ | 85/100 [01:07<00:12,  1.23steps/s, loss=0.024870196]     86%|████████▌ | 86/100 [01:08<00:12,  1.12steps/s, loss=0.024870196]     86%|████████▌ | 86/100 [01:08<00:12,  1.12steps/s, loss=0.024834244]     87%|████████▋ | 87/100 [01:09<00:11,  1.14steps/s, loss=0.024834244]     87%|████████▋ | 87/100 [01:09<00:11,  1.14steps/s, loss=0.024850488]     88%|████████▊ | 88/100 [01:10<00:10,  1.15steps/s, loss=0.024850488]     88%|████████▊ | 88/100 [01:10<00:10,  1.15steps/s, loss=0.024812043]     89%|████████▉ | 89/100 [01:11<00:09,  1.14steps/s, loss=0.024812043]     89%|████████▉ | 89/100 [01:11<00:09,  1.14steps/s, loss=0.02480093]      90%|█████████ | 90/100 [01:12<00:08,  1.16steps/s, loss=0.02480093]     90%|█████████ | 90/100 [01:12<00:08,  1.16steps/s, loss=0.024541914]     91%|█████████ | 91/100 [01:12<00:07,  1.17steps/s, loss=0.024541914]     91%|█████████ | 91/100 [01:13<00:07,  1.17steps/s, loss=0.025406478]     92%|█████████▏| 92/100 [01:13<00:06,  1.18steps/s, loss=0.025406478]     92%|█████████▏| 92/100 [01:13<00:06,  1.18steps/s, loss=0.024891404]     93%|█████████▎| 93/100 [01:14<00:05,  1.20steps/s, loss=0.024891404]     93%|█████████▎| 93/100 [01:14<00:05,  1.20steps/s, loss=0.02507006]      94%|█████████▍| 94/100 [01:15<00:04,  1.20steps/s, loss=0.02507006]     94%|█████████▍| 94/100 [01:15<00:04,  1.20steps/s, loss=0.024781264]     95%|█████████▌| 95/100 [01:16<00:04,  1.12steps/s, loss=0.024781264]     95%|█████████▌| 95/100 [01:16<00:04,  1.12steps/s, loss=0.024829218]     96%|█████████▌| 96/100 [01:17<00:03,  1.15steps/s, loss=0.024829218]     96%|█████████▌| 96/100 [01:17<00:03,  1.15steps/s, loss=0.024508622]     97%|█████████▋| 97/100 [01:18<00:02,  1.16steps/s, loss=0.024508622]     97%|█████████▋| 97/100 [01:18<00:02,  1.16steps/s, loss=0.024713859]     98%|█████████▊| 98/100 [01:18<00:01,  1.16steps/s, loss=0.024713859]     98%|█████████▊| 98/100 [01:19<00:01,  1.16steps/s, loss=0.024637267]     99%|█████████▉| 99/100 [01:19<00:00,  1.16steps/s, loss=0.024637267]     99%|█████████▉| 99/100 [01:20<00:00,  1.16steps/s, loss=0.024590464]    100%|██████████| 100/100 [01:20<00:00,  1.17steps/s, loss=0.024590464]    100%|██████████| 100/100 [01:20<00:00,  1.24steps/s, loss=0.024590464]




.. GENERATED FROM PYTHON SOURCE LINES 244-248

.. image-sg:: /generated/autoexamples/GPU/images/mrinufft_learn_traj_mc.gif
   :alt: example learn_samples
   :srcset: /generated/autoexamples/GPU/images/mrinufft_learn_traj_mc.gif
   :class: sphx-glr-single-img

.. GENERATED FROM PYTHON SOURCE LINES 250-252

Trained trajectory
------------------

.. GENERATED FROM PYTHON SOURCE LINES 252-259

.. code-block:: Python

    model.eval()
    recon = model(mcmri_2D)
    fig, axs = plt.subplots(2, 2, figsize=(10, 10))
    plot_state(axs, mri_2D, model.trajectory.detach().cpu().numpy(), recon, losses)
    plt.show()





.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_003.png
   :alt: MR Image, Trajectory, Reconstruction, Loss
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 260-275

References
==========

.. [Proj] N. Chauffert, P. Weiss, J. Kahn and P. Ciuciu, "A Projection Algorithm for
          Gradient Waveforms Design in Magnetic Resonance Imaging," in
          IEEE Transactions on Medical Imaging, vol. 35, no. 9, pp. 2026-2039, Sept. 2016,
          doi: 10.1109/TMI.2016.2544251.
.. [Sparks] G. R. Chaithya, P. Weiss, G. Daval-Frérot, A. Massire, A. Vignaud and P. Ciuciu,
          "Optimizing Full 3D SPARKLING Trajectories for High-Resolution Magnetic
          Resonance Imaging," in IEEE Transactions on Medical Imaging, vol. 41, no. 8,
          pp. 2105-2117, Aug. 2022, doi: 10.1109/TMI.2022.3157269.
.. [Projector] Chaithya GR, and Philippe Ciuciu. 2023. "Jointly Learning Non-Cartesian
          k-Space Trajectories and Reconstruction Networks for 2D and 3D MR Imaging
          through Projection" Bioengineering 10, no. 2: 158.
          https://doi.org/10.3390/bioengineering10020158


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 28.148 seconds)


.. _sphx_glr_download_generated_autoexamples_GPU_example_learn_samples_multicoil.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/mind-inria/mri-nufft/gh-pages?urlpath=lab/tree/examples/generated/autoexamples/GPU/example_learn_samples_multicoil.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: example_learn_samples_multicoil.ipynb <example_learn_samples_multicoil.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: example_learn_samples_multicoil.py <example_learn_samples_multicoil.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: example_learn_samples_multicoil.zip <example_learn_samples_multicoil.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
