
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "generated/autoexamples/example_learn_samples_multires.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_generated_autoexamples_example_learn_samples_multires.py>`
        to download the full example code. or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_generated_autoexamples_example_learn_samples_multires.py:


===============================================
Learn Sampling pattern with multi-resolution
===============================================

A small pytorch example to showcase learning k-space sampling patterns.
This example showcases the auto-diff capabilities of the NUFFT operator 
wrt to k-space trajectory in mri-nufft.

In this example we learn the k-space samples :math:`\mathbf{K}` for the following cost function:

.. math::
    \mathbf{\hat{K}} =  arg \min_{\mathbf{K}} ||  \mathcal{F}_\mathbf{K}^* D_\mathbf{K} \mathcal{F}_\mathbf{K} \mathbf{x} - \mathbf{x} ||_2^2
    
where :math:`\mathcal{F}_\mathbf{K}` is the forward NUFFT operator and :math:`D_\mathbf{K}` is the density compensators for trajectory :math:`\mathbf{K}`,  :math:`\mathbf{x}` is the MR image which is also the target image to be reconstructed.

Additionally, in-order to converge faster, we also learn the trajectory in a multi-resolution fashion. This is done by first optimizing a 8 times decimated trajectory locations, called control points. After a fixed number of iterations (5 in this example), these control points are upscaled by a factor of 2. However, note that the NUFFT operator always holds linearly interpolated version of the control points as k-space sampling trajectory.

.. note::
    This example can run on a binder instance as it is purely CPU based backend (finufft), and is restricted to a 2D single coil toy case.

.. warning::
    This example only showcases the autodiff capabilities, the learned sampling pattern is not scanner compliant as the scanner gradients required to implement it violate the hardware constraints. In practice, a projection :math:`\Pi_\mathcal{Q}(\mathbf{K})` into the scanner constraints set :math:`\mathcal{Q}` is recommended (see [Proj]_). This is implemented in the proprietary SPARKLING package [Sparks]_. Users are encouraged to contact the authors if they want to use it.

.. GENERATED FROM PYTHON SOURCE LINES 27-31

.. colab-link::
   :needs_gpu: 0

   !pip install mri-nufft[finufft]

.. GENERATED FROM PYTHON SOURCE LINES 33-35

Imports
-------

.. GENERATED FROM PYTHON SOURCE LINES 35-49

.. code-block:: Python


    import time
    import joblib

    import brainweb_dl as bwdl
    import matplotlib.pyplot as plt
    import numpy as np
    import torch
    from tqdm import tqdm
    from PIL import Image, ImageSequence

    from mrinufft import get_operator
    from mrinufft.trajectories import initialize_2D_radial








.. GENERATED FROM PYTHON SOURCE LINES 50-55

Setup a simple class to learn trajectory
----------------------------------------
.. note::
    While we are only learning the NUFFT operator, we still need the gradient `wrt_data=True` to have all the gradients computed correctly.
    See [Projector]_ for more details.

.. GENERATED FROM PYTHON SOURCE LINES 55-118

.. code-block:: Python



    class Model(torch.nn.Module):
        def __init__(
            self,
            inital_trajectory,
            img_size=(256, 256),
            start_decim=8,
            interpolation_mode="linear",
        ):
            super(Model, self).__init__()
            self.control = torch.nn.Parameter(
                data=torch.Tensor(inital_trajectory[:, ::start_decim]),
                requires_grad=True,
            )
            self.current_decim = start_decim
            self.interpolation_mode = interpolation_mode
            sample_points = inital_trajectory.reshape(-1, inital_trajectory.shape[-1])
            self.operator = get_operator("finufft", wrt_data=True, wrt_traj=True)(
                sample_points,
                shape=img_size,
                squeeze_dims=False,
            )
            self.img_size = img_size

        def _interpolate(self, traj, factor=2):
            """Torch interpolate function to upsample the trajectory"""
            return torch.nn.functional.interpolate(
                traj.moveaxis(1, -1),
                scale_factor=factor,
                mode=self.interpolation_mode,
                align_corners=True,
            ).moveaxis(-1, 1)

        def get_trajectory(self):
            """Function to get trajectory, which is interpolated version of control points."""
            traj = self.control.clone()
            for i in range(np.log2(self.current_decim).astype(int)):
                traj = self._interpolate(traj)

            return traj.reshape(-1, traj.shape[-1])

        def upscale(self, factor=2):
            """Upscaling the model.
            In this step, the number of control points are doubled and interpolated.
            """
            self.control = torch.nn.Parameter(
                data=self._interpolate(self.control),
                requires_grad=True,
            )
            self.current_decim /= factor

        def forward(self, x):
            traj = self.get_trajectory()
            self.operator.samples = traj

            # Simulate the acquisition process
            kspace = self.operator.op(x)

            adjoint = self.operator.adj_op(kspace).abs()
            return adjoint / torch.mean(adjoint)









.. GENERATED FROM PYTHON SOURCE LINES 119-121

Util function to plot the state of the model
--------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 121-174

.. code-block:: Python



    def plot_state(
        axs, mri_2D, traj, recon, control_points=None, loss=None, save_name=None
    ):
        axs = axs.flatten()
        axs[0].imshow(np.abs(mri_2D[0]), cmap="gray")
        axs[0].axis("off")
        axs[0].set_title("MR Image")
        axs[1].scatter(*traj.T, s=0.5)
        if control_points is not None:
            axs[1].scatter(*control_points.T, s=1, color="r")
            axs[1].legend(["Trajectory", "Control Points"])
        axs[1].set_title("Trajectory")
        axs[2].imshow(np.abs(recon[0][0].detach().cpu().numpy()), cmap="gray")
        axs[2].axis("off")
        axs[2].set_title("Reconstruction")
        if loss is not None:
            axs[3].plot(loss)
            axs[3].grid("on")
            axs[3].set_title("Loss")
        if save_name is not None:
            plt.savefig(save_name, bbox_inches="tight")
            plt.close()
        else:
            plt.show()


    def upsample_optimizer(optimizer, new_optimizer, factor=2):
        """Upsample the optimizer."""
        for old_group, new_group in zip(optimizer.param_groups, new_optimizer.param_groups):
            for old_param, new_param in zip(old_group["params"], new_group["params"]):
                # Interpolate optimizer states
                if old_param in optimizer.state:
                    for key in optimizer.state[old_param].keys():
                        if isinstance(optimizer.state[old_param][key], torch.Tensor):
                            old_state = optimizer.state[old_param][key]
                            if old_state.ndim == 0:
                                new_state = old_state
                            else:
                                new_state = torch.nn.functional.interpolate(
                                    old_state.moveaxis(1, -1),
                                    scale_factor=factor,
                                    mode="linear",
                                ).moveaxis(-1, 1)
                            new_optimizer.state[new_param][key] = new_state
                        else:
                            new_optimizer.state[new_param][key] = optimizer.state[
                                old_param
                            ][key]
        return new_optimizer









.. GENERATED FROM PYTHON SOURCE LINES 175-178

Setup Inputs (models, trajectory and image)
-------------------------------------------
First we create the model with a simple radial trajectory (32 shots of 256 points)

.. GENERATED FROM PYTHON SOURCE LINES 178-183

.. code-block:: Python


    init_traj = initialize_2D_radial(32, 256).astype(np.float32)
    model = Model(init_traj, img_size=(256, 256))
    model.eval()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /volatile/github-ci-mind-inria/action-runner/_work/_tool/Python/3.10.14/x64/lib/python3.10/site-packages/mrinufft/_utils.py:94: UserWarning: Samples will be rescaled to [-pi, pi), assuming they were in [-0.5, 0.5)
      warnings.warn(

    Model(
      (operator): MRINufftAutoGrad()
    )



.. GENERATED FROM PYTHON SOURCE LINES 184-188

The image on which we are going to train.
.. note ::
   In practice we would use instead a dataset (e.g. fastMRI)


.. GENERATED FROM PYTHON SOURCE LINES 188-204

.. code-block:: Python


    mri_2D = torch.from_numpy(np.flipud(bwdl.get_mri(4, "T1")[80, ...]).astype(np.float32))[
        None
    ]
    mri_2D = mri_2D / torch.mean(mri_2D)


    # Initialisation
    # --------------
    # Before training, here is the simple reconstruction we have using a
    # density compensated adjoint.

    recon = model(mri_2D)
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    plot_state(axs, mri_2D, init_traj, recon, model.control.detach().cpu().numpy())




.. image-sg:: /generated/autoexamples/images/sphx_glr_example_learn_samples_multires_001.png
   :alt: MR Image, Trajectory, Reconstruction
   :srcset: /generated/autoexamples/images/sphx_glr_example_learn_samples_multires_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /volatile/github-ci-mind-inria/action-runner/_work/_tool/Python/3.10.14/x64/lib/python3.10/site-packages/mrinufft/_utils.py:94: UserWarning: Samples will be rescaled to [-pi, pi), assuming they were in [-0.5, 0.5)
      warnings.warn(
    /volatile/github-ci-mind-inria/action-runner/_work/_tool/Python/3.10.14/x64/lib/python3.10/site-packages/finufft/_interfaces.py:329: UserWarning: Argument `data` does not satisfy the following requirement: C. Copying array (this may reduce performance)
      warnings.warn(f"Argument `{name}` does not satisfy the following requirement: {prop}. Copying array (this may reduce performance)")




.. GENERATED FROM PYTHON SOURCE LINES 205-207

Start training loop
-------------------

.. GENERATED FROM PYTHON SOURCE LINES 207-265

.. code-block:: Python

    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    losses = []
    image_files = []
    model.train()
    while model.current_decim >= 1:
        with tqdm(range(30), unit="steps") as tqdms:
            for i in tqdms:
                out = model(mri_2D)
                loss = torch.nn.functional.mse_loss(out, mri_2D[None, None])
                numpy_loss = (loss.detach().cpu().numpy(),)

                tqdms.set_postfix({"loss": numpy_loss})
                losses.append(numpy_loss)
                optimizer.zero_grad()
                loss.backward()

                optimizer.step()
                with torch.no_grad():
                    # Clamp the value of trajectory between [-0.5, 0.5]
                    for param in model.parameters():
                        param.clamp_(-0.5, 0.5)
                # Generate images for gif
                hashed = joblib.hash((i, "learn_traj", time.time()))
                filename = "/tmp/" + f"{hashed}.png"
                plt.clf()
                fig, axs = plt.subplots(2, 2, figsize=(10, 10), num=1)
                plot_state(
                    axs,
                    mri_2D,
                    model.get_trajectory().detach().cpu().numpy(),
                    out,
                    model.control.detach().cpu().numpy(),
                    losses,
                    save_name=filename,
                )
                image_files.append(filename)
            if model.current_decim == 1:
                break
            else:
                model.upscale()
                optimizer = upsample_optimizer(
                    optimizer, torch.optim.Adam(model.parameters(), lr=1e-3)
                )


    # Make a GIF of all images.
    imgs = [Image.open(img) for img in image_files]
    imgs[0].save(
        "mrinufft_learn_traj_multires.gif",
        save_all=True,
        append_images=imgs[1:],
        optimize=False,
        duration=2,
        loop=0,
    )

    # sphinx_gallery_thumbnail_path = 'generated/autoexamples/images/mrinufft_learn_traj_multires.gif'





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/30 [00:00<?, ?steps/s]/volatile/github-ci-mind-inria/action-runner/_work/_tool/Python/3.10.14/x64/lib/python3.10/site-packages/mrinufft/_utils.py:94: UserWarning: Samples will be rescaled to [-pi, pi), assuming they were in [-0.5, 0.5)
      warnings.warn(
    /volatile/github-ci-mind-inria/action-runner/_work/_tool/Python/3.10.14/x64/lib/python3.10/site-packages/finufft/_interfaces.py:329: UserWarning: Argument `data` does not satisfy the following requirement: C. Copying array (this may reduce performance)
      warnings.warn(f"Argument `{name}` does not satisfy the following requirement: {prop}. Copying array (this may reduce performance)")
    /volatile/github-ci-mind-inria/action-runner/_work/mri-nufft/mri-nufft/examples/example_learn_samples_multires.py:215: UserWarning: Using a target size (torch.Size([1, 1, 1, 256, 256])) that is different to the input size (torch.Size([1, 1, 256, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
      loss = torch.nn.functional.mse_loss(out, mri_2D[None, None])
      0%|          | 0/30 [00:00<?, ?steps/s, loss=(array(0.7415447, dtype=float32),)]/volatile/github-ci-mind-inria/action-runner/_work/_tool/Python/3.10.14/x64/lib/python3.10/site-packages/mrinufft/operators/autodiff.py:98: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:305.)
      grad_traj = torch.transpose(torch.sum(grad_traj, dim=1), 0, 1).to(
      3%|▎         | 1/30 [00:00<00:28,  1.01steps/s, loss=(array(0.7415447, dtype=float32),)]      3%|▎         | 1/30 [00:01<00:28,  1.01steps/s, loss=(array(0.6619946, dtype=float32),)]      7%|▋         | 2/30 [00:01<00:27,  1.00steps/s, loss=(array(0.6619946, dtype=float32),)]      7%|▋         | 2/30 [00:02<00:27,  1.00steps/s, loss=(array(0.57360345, dtype=float32),)]     10%|█         | 3/30 [00:03<00:27,  1.00s/steps, loss=(array(0.57360345, dtype=float32),)]     10%|█         | 3/30 [00:03<00:27,  1.00s/steps, loss=(array(0.48102552, dtype=float32),)]     13%|█▎        | 4/30 [00:03<00:25,  1.01steps/s, loss=(array(0.48102552, dtype=float32),)]     13%|█▎        | 4/30 [00:03<00:25,  1.01steps/s, loss=(array(0.3928566, dtype=float32),)]      17%|█▋        | 5/30 [00:04<00:24,  1.01steps/s, loss=(array(0.3928566, dtype=float32),)]     17%|█▋        | 5/30 [00:04<00:24,  1.01steps/s, loss=(array(0.3241089, dtype=float32),)]     20%|██        | 6/30 [00:06<00:25,  1.08s/steps, loss=(array(0.3241089, dtype=float32),)]     20%|██        | 6/30 [00:06<00:25,  1.08s/steps, loss=(array(0.28962648, dtype=float32),)]     23%|██▎       | 7/30 [00:07<00:25,  1.11s/steps, loss=(array(0.28962648, dtype=float32),)]     23%|██▎       | 7/30 [00:07<00:25,  1.11s/steps, loss=(array(0.28672022, dtype=float32),)]     27%|██▋       | 8/30 [00:08<00:23,  1.08s/steps, loss=(array(0.28672022, dtype=float32),)]     27%|██▋       | 8/30 [00:08<00:23,  1.08s/steps, loss=(array(0.30415666, dtype=float32),)]     30%|███       | 9/30 [00:09<00:22,  1.05s/steps, loss=(array(0.30415666, dtype=float32),)]     30%|███       | 9/30 [00:09<00:22,  1.05s/steps, loss=(array(0.32396573, dtype=float32),)]     33%|███▎      | 10/30 [00:10<00:21,  1.07s/steps, loss=(array(0.32396573, dtype=float32),)]     33%|███▎      | 10/30 [00:10<00:21,  1.07s/steps, loss=(array(0.33222532, dtype=float32),)]     37%|███▋      | 11/30 [00:11<00:22,  1.19s/steps, loss=(array(0.33222532, dtype=float32),)]     37%|███▋      | 11/30 [00:12<00:22,  1.19s/steps, loss=(array(0.32644415, dtype=float32),)]     40%|████      | 12/30 [00:13<00:24,  1.37s/steps, loss=(array(0.32644415, dtype=float32),)]     40%|████      | 12/30 [00:13<00:24,  1.37s/steps, loss=(array(0.31118172, dtype=float32),)]     43%|████▎     | 13/30 [00:14<00:21,  1.24s/steps, loss=(array(0.31118172, dtype=float32),)]     43%|████▎     | 13/30 [00:14<00:21,  1.24s/steps, loss=(array(0.292948, dtype=float32),)]       47%|████▋     | 14/30 [00:15<00:18,  1.14s/steps, loss=(array(0.292948, dtype=float32),)]     47%|████▋     | 14/30 [00:15<00:18,  1.14s/steps, loss=(array(0.2773406, dtype=float32),)]     50%|█████     | 15/30 [00:16<00:17,  1.16s/steps, loss=(array(0.2773406, dtype=float32),)]     50%|█████     | 15/30 [00:16<00:17,  1.16s/steps, loss=(array(0.26735973, dtype=float32),)]     53%|█████▎    | 16/30 [00:17<00:15,  1.12s/steps, loss=(array(0.26735973, dtype=float32),)]     53%|█████▎    | 16/30 [00:17<00:15,  1.12s/steps, loss=(array(0.2631218, dtype=float32),)]      57%|█████▋    | 17/30 [00:18<00:14,  1.08s/steps, loss=(array(0.2631218, dtype=float32),)]     57%|█████▋    | 17/30 [00:18<00:14,  1.08s/steps, loss=(array(0.26294824, dtype=float32),)]     60%|██████    | 18/30 [00:20<00:14,  1.18s/steps, loss=(array(0.26294824, dtype=float32),)]     60%|██████    | 18/30 [00:20<00:14,  1.18s/steps, loss=(array(0.26474643, dtype=float32),)]     63%|██████▎   | 19/30 [00:21<00:12,  1.13s/steps, loss=(array(0.26474643, dtype=float32),)]     63%|██████▎   | 19/30 [00:21<00:12,  1.13s/steps, loss=(array(0.2668928, dtype=float32),)]      67%|██████▋   | 20/30 [00:22<00:11,  1.10s/steps, loss=(array(0.2668928, dtype=float32),)]     67%|██████▋   | 20/30 [00:22<00:11,  1.10s/steps, loss=(array(0.2681449, dtype=float32),)]     70%|███████   | 21/30 [00:23<00:09,  1.08s/steps, loss=(array(0.2681449, dtype=float32),)]     70%|███████   | 21/30 [00:23<00:09,  1.08s/steps, loss=(array(0.26755902, dtype=float32),)]     73%|███████▎  | 22/30 [00:24<00:08,  1.07s/steps, loss=(array(0.26755902, dtype=float32),)]     73%|███████▎  | 22/30 [00:24<00:08,  1.07s/steps, loss=(array(0.2649952, dtype=float32),)]      77%|███████▋  | 23/30 [00:26<00:08,  1.27s/steps, loss=(array(0.2649952, dtype=float32),)]     77%|███████▋  | 23/30 [00:26<00:08,  1.27s/steps, loss=(array(0.2610227, dtype=float32),)]     80%|████████  | 24/30 [00:27<00:07,  1.27s/steps, loss=(array(0.2610227, dtype=float32),)]     80%|████████  | 24/30 [00:27<00:07,  1.27s/steps, loss=(array(0.25650465, dtype=float32),)]     83%|████████▎ | 25/30 [00:28<00:06,  1.23s/steps, loss=(array(0.25650465, dtype=float32),)]     83%|████████▎ | 25/30 [00:28<00:06,  1.23s/steps, loss=(array(0.25223807, dtype=float32),)]     87%|████████▋ | 26/30 [00:29<00:04,  1.17s/steps, loss=(array(0.25223807, dtype=float32),)]     87%|████████▋ | 26/30 [00:29<00:04,  1.17s/steps, loss=(array(0.24871585, dtype=float32),)]     90%|█████████ | 27/30 [00:30<00:03,  1.16s/steps, loss=(array(0.24871585, dtype=float32),)]     90%|█████████ | 27/30 [00:30<00:03,  1.16s/steps, loss=(array(0.24605149, dtype=float32),)]     93%|█████████▎| 28/30 [00:31<00:02,  1.17s/steps, loss=(array(0.24605149, dtype=float32),)]     93%|█████████▎| 28/30 [00:31<00:02,  1.17s/steps, loss=(array(0.2441479, dtype=float32),)]      97%|█████████▋| 29/30 [00:33<00:01,  1.18s/steps, loss=(array(0.2441479, dtype=float32),)]     97%|█████████▋| 29/30 [00:33<00:01,  1.18s/steps, loss=(array(0.24282919, dtype=float32),)]    100%|██████████| 30/30 [00:34<00:00,  1.18s/steps, loss=(array(0.24282919, dtype=float32),)]    100%|██████████| 30/30 [00:34<00:00,  1.14s/steps, loss=(array(0.24282919, dtype=float32),)]
      0%|          | 0/30 [00:00<?, ?steps/s]      0%|          | 0/30 [00:00<?, ?steps/s, loss=(array(0.24185976, dtype=float32),)]      3%|▎         | 1/30 [00:01<00:42,  1.47s/steps, loss=(array(0.24185976, dtype=float32),)]      3%|▎         | 1/30 [00:01<00:42,  1.47s/steps, loss=(array(0.24115999, dtype=float32),)]      7%|▋         | 2/30 [00:02<00:38,  1.39s/steps, loss=(array(0.24115999, dtype=float32),)]      7%|▋         | 2/30 [00:02<00:38,  1.39s/steps, loss=(array(0.24021481, dtype=float32),)]     10%|█         | 3/30 [00:03<00:34,  1.29s/steps, loss=(array(0.24021481, dtype=float32),)]     10%|█         | 3/30 [00:03<00:34,  1.29s/steps, loss=(array(0.23891634, dtype=float32),)]     13%|█▎        | 4/30 [00:05<00:31,  1.20s/steps, loss=(array(0.23891634, dtype=float32),)]     13%|█▎        | 4/30 [00:05<00:31,  1.20s/steps, loss=(array(0.23723194, dtype=float32),)]     17%|█▋        | 5/30 [00:06<00:31,  1.24s/steps, loss=(array(0.23723194, dtype=float32),)]     17%|█▋        | 5/30 [00:06<00:31,  1.24s/steps, loss=(array(0.23520598, dtype=float32),)]     20%|██        | 6/30 [00:07<00:31,  1.31s/steps, loss=(array(0.23520598, dtype=float32),)]     20%|██        | 6/30 [00:07<00:31,  1.31s/steps, loss=(array(0.23294458, dtype=float32),)]     23%|██▎       | 7/30 [00:08<00:28,  1.23s/steps, loss=(array(0.23294458, dtype=float32),)]     23%|██▎       | 7/30 [00:08<00:28,  1.23s/steps, loss=(array(0.23059043, dtype=float32),)]     27%|██▋       | 8/30 [00:09<00:25,  1.16s/steps, loss=(array(0.23059043, dtype=float32),)]     27%|██▋       | 8/30 [00:09<00:25,  1.16s/steps, loss=(array(0.22829056, dtype=float32),)]     30%|███       | 9/30 [00:11<00:26,  1.28s/steps, loss=(array(0.22829056, dtype=float32),)]     30%|███       | 9/30 [00:11<00:26,  1.28s/steps, loss=(array(0.22616613, dtype=float32),)]     33%|███▎      | 10/30 [00:12<00:27,  1.35s/steps, loss=(array(0.22616613, dtype=float32),)]     33%|███▎      | 10/30 [00:12<00:27,  1.35s/steps, loss=(array(0.22428975, dtype=float32),)]     37%|███▋      | 11/30 [00:13<00:23,  1.26s/steps, loss=(array(0.22428975, dtype=float32),)]     37%|███▋      | 11/30 [00:14<00:23,  1.26s/steps, loss=(array(0.22266981, dtype=float32),)]     40%|████      | 12/30 [00:15<00:23,  1.28s/steps, loss=(array(0.22266981, dtype=float32),)]     40%|████      | 12/30 [00:15<00:23,  1.28s/steps, loss=(array(0.22125773, dtype=float32),)]     43%|████▎     | 13/30 [00:16<00:21,  1.25s/steps, loss=(array(0.22125773, dtype=float32),)]     43%|████▎     | 13/30 [00:16<00:21,  1.25s/steps, loss=(array(0.21997207, dtype=float32),)]     47%|████▋     | 14/30 [00:17<00:18,  1.16s/steps, loss=(array(0.21997207, dtype=float32),)]     47%|████▋     | 14/30 [00:17<00:18,  1.16s/steps, loss=(array(0.21872865, dtype=float32),)]     50%|█████     | 15/30 [00:18<00:17,  1.16s/steps, loss=(array(0.21872865, dtype=float32),)]     50%|█████     | 15/30 [00:18<00:17,  1.16s/steps, loss=(array(0.21746632, dtype=float32),)]     53%|█████▎    | 16/30 [00:20<00:17,  1.23s/steps, loss=(array(0.21746632, dtype=float32),)]     53%|█████▎    | 16/30 [00:20<00:17,  1.23s/steps, loss=(array(0.21615997, dtype=float32),)]     57%|█████▋    | 17/30 [00:21<00:16,  1.23s/steps, loss=(array(0.21615997, dtype=float32),)]     57%|█████▋    | 17/30 [00:21<00:16,  1.23s/steps, loss=(array(0.21481836, dtype=float32),)]     60%|██████    | 18/30 [00:22<00:16,  1.37s/steps, loss=(array(0.21481836, dtype=float32),)]     60%|██████    | 18/30 [00:22<00:16,  1.37s/steps, loss=(array(0.21347004, dtype=float32),)]     63%|██████▎   | 19/30 [00:24<00:14,  1.30s/steps, loss=(array(0.21347004, dtype=float32),)]     63%|██████▎   | 19/30 [00:24<00:14,  1.30s/steps, loss=(array(0.21214774, dtype=float32),)]     67%|██████▋   | 20/30 [00:25<00:12,  1.25s/steps, loss=(array(0.21214774, dtype=float32),)]     67%|██████▋   | 20/30 [00:25<00:12,  1.25s/steps, loss=(array(0.2108762, dtype=float32),)]      70%|███████   | 21/30 [00:26<00:11,  1.23s/steps, loss=(array(0.2108762, dtype=float32),)]     70%|███████   | 21/30 [00:26<00:11,  1.23s/steps, loss=(array(0.209667, dtype=float32),)]      73%|███████▎  | 22/30 [00:27<00:09,  1.24s/steps, loss=(array(0.209667, dtype=float32),)]     73%|███████▎  | 22/30 [00:27<00:09,  1.24s/steps, loss=(array(0.20851952, dtype=float32),)]     77%|███████▋  | 23/30 [00:28<00:08,  1.24s/steps, loss=(array(0.20851952, dtype=float32),)]     77%|███████▋  | 23/30 [00:28<00:08,  1.24s/steps, loss=(array(0.20742238, dtype=float32),)]     80%|████████  | 24/30 [00:30<00:07,  1.22s/steps, loss=(array(0.20742238, dtype=float32),)]     80%|████████  | 24/30 [00:30<00:07,  1.22s/steps, loss=(array(0.20635855, dtype=float32),)]     83%|████████▎ | 25/30 [00:31<00:05,  1.14s/steps, loss=(array(0.20635855, dtype=float32),)]     83%|████████▎ | 25/30 [00:31<00:05,  1.14s/steps, loss=(array(0.2053109, dtype=float32),)]      87%|████████▋ | 26/30 [00:32<00:04,  1.14s/steps, loss=(array(0.2053109, dtype=float32),)]     87%|████████▋ | 26/30 [00:32<00:04,  1.14s/steps, loss=(array(0.20426537, dtype=float32),)]     90%|█████████ | 27/30 [00:33<00:03,  1.21s/steps, loss=(array(0.20426537, dtype=float32),)]     90%|█████████ | 27/30 [00:33<00:03,  1.21s/steps, loss=(array(0.20321333, dtype=float32),)]     93%|█████████▎| 28/30 [00:34<00:02,  1.20s/steps, loss=(array(0.20321333, dtype=float32),)]     93%|█████████▎| 28/30 [00:34<00:02,  1.20s/steps, loss=(array(0.2021533, dtype=float32),)]      97%|█████████▋| 29/30 [00:35<00:01,  1.19s/steps, loss=(array(0.2021533, dtype=float32),)]     97%|█████████▋| 29/30 [00:35<00:01,  1.19s/steps, loss=(array(0.2010901, dtype=float32),)]    100%|██████████| 30/30 [00:37<00:00,  1.17s/steps, loss=(array(0.2010901, dtype=float32),)]    100%|██████████| 30/30 [00:37<00:00,  1.23s/steps, loss=(array(0.2010901, dtype=float32),)]
      0%|          | 0/30 [00:00<?, ?steps/s]      0%|          | 0/30 [00:00<?, ?steps/s, loss=(array(0.20003127, dtype=float32),)]      3%|▎         | 1/30 [00:01<00:37,  1.30s/steps, loss=(array(0.20003127, dtype=float32),)]      3%|▎         | 1/30 [00:01<00:37,  1.30s/steps, loss=(array(0.19908883, dtype=float32),)]      7%|▋         | 2/30 [00:02<00:31,  1.13s/steps, loss=(array(0.19908883, dtype=float32),)]      7%|▋         | 2/30 [00:02<00:31,  1.13s/steps, loss=(array(0.19816712, dtype=float32),)]     10%|█         | 3/30 [00:03<00:29,  1.10s/steps, loss=(array(0.19816712, dtype=float32),)]     10%|█         | 3/30 [00:03<00:29,  1.10s/steps, loss=(array(0.197264, dtype=float32),)]       13%|█▎        | 4/30 [00:04<00:26,  1.03s/steps, loss=(array(0.197264, dtype=float32),)]     13%|█▎        | 4/30 [00:04<00:26,  1.03s/steps, loss=(array(0.1963764, dtype=float32),)]     17%|█▋        | 5/30 [00:05<00:24,  1.02steps/s, loss=(array(0.1963764, dtype=float32),)]     17%|█▋        | 5/30 [00:05<00:24,  1.02steps/s, loss=(array(0.19550219, dtype=float32),)]     20%|██        | 6/30 [00:06<00:25,  1.07s/steps, loss=(array(0.19550219, dtype=float32),)]     20%|██        | 6/30 [00:06<00:25,  1.07s/steps, loss=(array(0.1946412, dtype=float32),)]      23%|██▎       | 7/30 [00:07<00:25,  1.10s/steps, loss=(array(0.1946412, dtype=float32),)]     23%|██▎       | 7/30 [00:07<00:25,  1.10s/steps, loss=(array(0.19379511, dtype=float32),)]     27%|██▋       | 8/30 [00:08<00:24,  1.09s/steps, loss=(array(0.19379511, dtype=float32),)]     27%|██▋       | 8/30 [00:08<00:24,  1.09s/steps, loss=(array(0.19296736, dtype=float32),)]     30%|███       | 9/30 [00:09<00:22,  1.07s/steps, loss=(array(0.19296736, dtype=float32),)]     30%|███       | 9/30 [00:09<00:22,  1.07s/steps, loss=(array(0.19216225, dtype=float32),)]     33%|███▎      | 10/30 [00:10<00:20,  1.03s/steps, loss=(array(0.19216225, dtype=float32),)]     33%|███▎      | 10/30 [00:10<00:20,  1.03s/steps, loss=(array(0.19138326, dtype=float32),)]     37%|███▋      | 11/30 [00:11<00:19,  1.00s/steps, loss=(array(0.19138326, dtype=float32),)]     37%|███▋      | 11/30 [00:11<00:19,  1.00s/steps, loss=(array(0.19063196, dtype=float32),)]     40%|████      | 12/30 [00:12<00:19,  1.06s/steps, loss=(array(0.19063196, dtype=float32),)]     40%|████      | 12/30 [00:12<00:19,  1.06s/steps, loss=(array(0.18990812, dtype=float32),)]     43%|████▎     | 13/30 [00:13<00:17,  1.01s/steps, loss=(array(0.18990812, dtype=float32),)]     43%|████▎     | 13/30 [00:13<00:17,  1.01s/steps, loss=(array(0.18920961, dtype=float32),)]     47%|████▋     | 14/30 [00:15<00:17,  1.12s/steps, loss=(array(0.18920961, dtype=float32),)]     47%|████▋     | 14/30 [00:15<00:17,  1.12s/steps, loss=(array(0.1885336, dtype=float32),)]      50%|█████     | 15/30 [00:16<00:16,  1.12s/steps, loss=(array(0.1885336, dtype=float32),)]     50%|█████     | 15/30 [00:16<00:16,  1.12s/steps, loss=(array(0.18787697, dtype=float32),)]     53%|█████▎    | 16/30 [00:17<00:17,  1.28s/steps, loss=(array(0.18787697, dtype=float32),)]     53%|█████▎    | 16/30 [00:17<00:17,  1.28s/steps, loss=(array(0.18723741, dtype=float32),)]     57%|█████▋    | 17/30 [00:19<00:17,  1.34s/steps, loss=(array(0.18723741, dtype=float32),)]     57%|█████▋    | 17/30 [00:19<00:17,  1.34s/steps, loss=(array(0.18661356, dtype=float32),)]     60%|██████    | 18/30 [00:20<00:16,  1.36s/steps, loss=(array(0.18661356, dtype=float32),)]     60%|██████    | 18/30 [00:20<00:16,  1.36s/steps, loss=(array(0.18600509, dtype=float32),)]     63%|██████▎   | 19/30 [00:22<00:15,  1.39s/steps, loss=(array(0.18600509, dtype=float32),)]     63%|██████▎   | 19/30 [00:22<00:15,  1.39s/steps, loss=(array(0.18541184, dtype=float32),)]     67%|██████▋   | 20/30 [00:23<00:14,  1.40s/steps, loss=(array(0.18541184, dtype=float32),)]     67%|██████▋   | 20/30 [00:23<00:14,  1.40s/steps, loss=(array(0.18483369, dtype=float32),)]     70%|███████   | 21/30 [00:24<00:11,  1.30s/steps, loss=(array(0.18483369, dtype=float32),)]     70%|███████   | 21/30 [00:24<00:11,  1.30s/steps, loss=(array(0.18427025, dtype=float32),)]     73%|███████▎  | 22/30 [00:25<00:09,  1.23s/steps, loss=(array(0.18427025, dtype=float32),)]     73%|███████▎  | 22/30 [00:25<00:09,  1.23s/steps, loss=(array(0.18372053, dtype=float32),)]     77%|███████▋  | 23/30 [00:27<00:09,  1.32s/steps, loss=(array(0.18372053, dtype=float32),)]     77%|███████▋  | 23/30 [00:27<00:09,  1.32s/steps, loss=(array(0.18318284, dtype=float32),)]     80%|████████  | 24/30 [00:28<00:07,  1.29s/steps, loss=(array(0.18318284, dtype=float32),)]     80%|████████  | 24/30 [00:28<00:07,  1.29s/steps, loss=(array(0.18265554, dtype=float32),)]     83%|████████▎ | 25/30 [00:29<00:06,  1.24s/steps, loss=(array(0.18265554, dtype=float32),)]     83%|████████▎ | 25/30 [00:29<00:06,  1.24s/steps, loss=(array(0.18213722, dtype=float32),)]     87%|████████▋ | 26/30 [00:30<00:04,  1.22s/steps, loss=(array(0.18213722, dtype=float32),)]     87%|████████▋ | 26/30 [00:30<00:04,  1.22s/steps, loss=(array(0.18162726, dtype=float32),)]     90%|█████████ | 27/30 [00:32<00:03,  1.23s/steps, loss=(array(0.18162726, dtype=float32),)]     90%|█████████ | 27/30 [00:32<00:03,  1.23s/steps, loss=(array(0.18112594, dtype=float32),)]     93%|█████████▎| 28/30 [00:33<00:02,  1.19s/steps, loss=(array(0.18112594, dtype=float32),)]     93%|█████████▎| 28/30 [00:33<00:02,  1.19s/steps, loss=(array(0.18063428, dtype=float32),)]     97%|█████████▋| 29/30 [00:34<00:01,  1.22s/steps, loss=(array(0.18063428, dtype=float32),)]     97%|█████████▋| 29/30 [00:34<00:01,  1.22s/steps, loss=(array(0.18015327, dtype=float32),)]    100%|██████████| 30/30 [00:35<00:00,  1.16s/steps, loss=(array(0.18015327, dtype=float32),)]    100%|██████████| 30/30 [00:35<00:00,  1.18s/steps, loss=(array(0.18015327, dtype=float32),)]
      0%|          | 0/30 [00:00<?, ?steps/s]      0%|          | 0/30 [00:00<?, ?steps/s, loss=(array(0.17968386, dtype=float32),)]      3%|▎         | 1/30 [00:01<00:37,  1.31s/steps, loss=(array(0.17968386, dtype=float32),)]      3%|▎         | 1/30 [00:01<00:37,  1.31s/steps, loss=(array(0.17922196, dtype=float32),)]      7%|▋         | 2/30 [00:02<00:40,  1.45s/steps, loss=(array(0.17922196, dtype=float32),)]      7%|▋         | 2/30 [00:02<00:40,  1.45s/steps, loss=(array(0.17875792, dtype=float32),)]     10%|█         | 3/30 [00:04<00:36,  1.35s/steps, loss=(array(0.17875792, dtype=float32),)]     10%|█         | 3/30 [00:04<00:36,  1.35s/steps, loss=(array(0.17829368, dtype=float32),)]     13%|█▎        | 4/30 [00:05<00:34,  1.33s/steps, loss=(array(0.17829368, dtype=float32),)]     13%|█▎        | 4/30 [00:05<00:34,  1.33s/steps, loss=(array(0.17783205, dtype=float32),)]     17%|█▋        | 5/30 [00:06<00:33,  1.35s/steps, loss=(array(0.17783205, dtype=float32),)]     17%|█▋        | 5/30 [00:06<00:33,  1.35s/steps, loss=(array(0.1773769, dtype=float32),)]      20%|██        | 6/30 [00:08<00:33,  1.41s/steps, loss=(array(0.1773769, dtype=float32),)]     20%|██        | 6/30 [00:08<00:33,  1.41s/steps, loss=(array(0.17693195, dtype=float32),)]     23%|██▎       | 7/30 [00:09<00:32,  1.41s/steps, loss=(array(0.17693195, dtype=float32),)]     23%|██▎       | 7/30 [00:09<00:32,  1.41s/steps, loss=(array(0.17650118, dtype=float32),)]     27%|██▋       | 8/30 [00:11<00:32,  1.46s/steps, loss=(array(0.17650118, dtype=float32),)]     27%|██▋       | 8/30 [00:11<00:32,  1.46s/steps, loss=(array(0.17608806, dtype=float32),)]     30%|███       | 9/30 [00:12<00:30,  1.44s/steps, loss=(array(0.17608806, dtype=float32),)]     30%|███       | 9/30 [00:12<00:30,  1.44s/steps, loss=(array(0.1756956, dtype=float32),)]      33%|███▎      | 10/30 [00:14<00:31,  1.57s/steps, loss=(array(0.1756956, dtype=float32),)]     33%|███▎      | 10/30 [00:14<00:31,  1.57s/steps, loss=(array(0.17532559, dtype=float32),)]     37%|███▋      | 11/30 [00:16<00:30,  1.63s/steps, loss=(array(0.17532559, dtype=float32),)]     37%|███▋      | 11/30 [00:16<00:30,  1.63s/steps, loss=(array(0.17497876, dtype=float32),)]     40%|████      | 12/30 [00:17<00:27,  1.50s/steps, loss=(array(0.17497876, dtype=float32),)]     40%|████      | 12/30 [00:17<00:27,  1.50s/steps, loss=(array(0.1746548, dtype=float32),)]      43%|████▎     | 13/30 [00:18<00:24,  1.42s/steps, loss=(array(0.1746548, dtype=float32),)]     43%|████▎     | 13/30 [00:18<00:24,  1.42s/steps, loss=(array(0.17435184, dtype=float32),)]     47%|████▋     | 14/30 [00:19<00:21,  1.36s/steps, loss=(array(0.17435184, dtype=float32),)]     47%|████▋     | 14/30 [00:19<00:21,  1.36s/steps, loss=(array(0.17406717, dtype=float32),)]     50%|█████     | 15/30 [00:21<00:20,  1.34s/steps, loss=(array(0.17406717, dtype=float32),)]     50%|█████     | 15/30 [00:21<00:20,  1.34s/steps, loss=(array(0.17379722, dtype=float32),)]     53%|█████▎    | 16/30 [00:22<00:18,  1.29s/steps, loss=(array(0.17379722, dtype=float32),)]     53%|█████▎    | 16/30 [00:22<00:18,  1.29s/steps, loss=(array(0.17353824, dtype=float32),)]     57%|█████▋    | 17/30 [00:23<00:16,  1.27s/steps, loss=(array(0.17353824, dtype=float32),)]     57%|█████▋    | 17/30 [00:23<00:16,  1.27s/steps, loss=(array(0.17328683, dtype=float32),)]     60%|██████    | 18/30 [00:24<00:14,  1.24s/steps, loss=(array(0.17328683, dtype=float32),)]     60%|██████    | 18/30 [00:24<00:14,  1.24s/steps, loss=(array(0.17304003, dtype=float32),)]     63%|██████▎   | 19/30 [00:25<00:13,  1.20s/steps, loss=(array(0.17304003, dtype=float32),)]     63%|██████▎   | 19/30 [00:25<00:13,  1.20s/steps, loss=(array(0.17279568, dtype=float32),)]     67%|██████▋   | 20/30 [00:27<00:12,  1.26s/steps, loss=(array(0.17279568, dtype=float32),)]     67%|██████▋   | 20/30 [00:27<00:12,  1.26s/steps, loss=(array(0.17255244, dtype=float32),)]     70%|███████   | 21/30 [00:28<00:11,  1.25s/steps, loss=(array(0.17255244, dtype=float32),)]     70%|███████   | 21/30 [00:28<00:11,  1.25s/steps, loss=(array(0.1723095, dtype=float32),)]      73%|███████▎  | 22/30 [00:29<00:09,  1.19s/steps, loss=(array(0.1723095, dtype=float32),)]     73%|███████▎  | 22/30 [00:29<00:09,  1.19s/steps, loss=(array(0.17206666, dtype=float32),)]     77%|███████▋  | 23/30 [00:30<00:07,  1.14s/steps, loss=(array(0.17206666, dtype=float32),)]     77%|███████▋  | 23/30 [00:30<00:07,  1.14s/steps, loss=(array(0.17182416, dtype=float32),)]     80%|████████  | 24/30 [00:31<00:07,  1.17s/steps, loss=(array(0.17182416, dtype=float32),)]     80%|████████  | 24/30 [00:31<00:07,  1.17s/steps, loss=(array(0.17158249, dtype=float32),)]     83%|████████▎ | 25/30 [00:32<00:05,  1.13s/steps, loss=(array(0.17158249, dtype=float32),)]     83%|████████▎ | 25/30 [00:32<00:05,  1.13s/steps, loss=(array(0.1713421, dtype=float32),)]      87%|████████▋ | 26/30 [00:33<00:04,  1.11s/steps, loss=(array(0.1713421, dtype=float32),)]     87%|████████▋ | 26/30 [00:33<00:04,  1.11s/steps, loss=(array(0.17110366, dtype=float32),)]     90%|█████████ | 27/30 [00:34<00:03,  1.06s/steps, loss=(array(0.17110366, dtype=float32),)]     90%|█████████ | 27/30 [00:34<00:03,  1.06s/steps, loss=(array(0.17086752, dtype=float32),)]     93%|█████████▎| 28/30 [00:35<00:02,  1.04s/steps, loss=(array(0.17086752, dtype=float32),)]     93%|█████████▎| 28/30 [00:35<00:02,  1.04s/steps, loss=(array(0.17063382, dtype=float32),)]     97%|█████████▋| 29/30 [00:37<00:01,  1.12s/steps, loss=(array(0.17063382, dtype=float32),)]     97%|█████████▋| 29/30 [00:37<00:01,  1.12s/steps, loss=(array(0.17040253, dtype=float32),)]    100%|██████████| 30/30 [00:38<00:00,  1.10s/steps, loss=(array(0.17040253, dtype=float32),)]    100%|██████████| 30/30 [00:38<00:00,  1.28s/steps, loss=(array(0.17040253, dtype=float32),)]




.. GENERATED FROM PYTHON SOURCE LINES 290-294

.. image-sg:: /generated/autoexamples/images/mrinufft_learn_traj_multires.gif
   :alt: example learn_samples
   :srcset: /generated/autoexamples/images/mrinufft_learn_traj_multires.gif
   :class: sphx-glr-single-img

.. GENERATED FROM PYTHON SOURCE LINES 296-298

Trained trajectory
------------------

.. GENERATED FROM PYTHON SOURCE LINES 298-311

.. code-block:: Python

    model.eval()
    recon = model(mri_2D)
    fig, axs = plt.subplots(2, 2, figsize=(10, 10))
    plot_state(
        axs,
        mri_2D,
        model.get_trajectory().detach().cpu().numpy(),
        recon=recon,
        control_points=None,
        loss=losses,
    )
    plt.show()




.. image-sg:: /generated/autoexamples/images/sphx_glr_example_learn_samples_multires_002.png
   :alt: MR Image, Trajectory, Reconstruction, Loss
   :srcset: /generated/autoexamples/images/sphx_glr_example_learn_samples_multires_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 312-318

.. note::
  The above learned trajectory is not that good because:
   - The trajectory is trained only for 5 iterations per decimation level, resulting in a suboptimal trajectory.
   - In order to make the example CPU compliant, we had to resort to preventing density compensation, hence the reconstructor is not good.

Users are requested to checkout :ref:`sphx_glr_generated_autoexamples_GPU_example_learn_samples.py` for example with density compensation.

.. GENERATED FROM PYTHON SOURCE LINES 320-335

References
==========

.. [Proj] N. Chauffert, P. Weiss, J. Kahn and P. Ciuciu, "A Projection Algorithm for
          Gradient Waveforms Design in Magnetic Resonance Imaging," in
          IEEE Transactions on Medical Imaging, vol. 35, no. 9, pp. 2026-2039, Sept. 2016,
          doi: 10.1109/TMI.2016.2544251.
.. [Sparks] G. R. Chaithya, P. Weiss, G. Daval-Frérot, A. Massire, A. Vignaud and P. Ciuciu,
          "Optimizing Full 3D SPARKLING Trajectories for High-Resolution Magnetic
          Resonance Imaging," in IEEE Transactions on Medical Imaging, vol. 41, no. 8,
          pp. 2105-2117, Aug. 2022, doi: 10.1109/TMI.2022.3157269.
.. [Projector] Chaithya GR, and Philippe Ciuciu. 2023. "Jointly Learning Non-Cartesian
          k-Space Trajectories and Reconstruction Networks for 2D and 3D MR Imaging
          through Projection" Bioengineering 10, no. 2: 158.
          https://doi.org/10.3390/bioengineering10020158


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (2 minutes 30.089 seconds)


.. _sphx_glr_download_generated_autoexamples_example_learn_samples_multires.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/mind-inria/mri-nufft/gh-pages?urlpath=lab/tree/examples/generated/autoexamples/example_learn_samples_multires.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: example_learn_samples_multires.ipynb <example_learn_samples_multires.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: example_learn_samples_multires.py <example_learn_samples_multires.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: example_learn_samples_multires.zip <example_learn_samples_multires.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
